{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdfe3ca1-8dcd-4d67-a9f0-24d1ae74f8cf",
   "metadata": {},
   "source": [
    "# Projet numérique de science des données 2021\n",
    "## LOUISOT Pierre \n",
    "## POLLET Florent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd306b34-3910-4c94-8648-550e23d1d6b6",
   "metadata": {},
   "source": [
    "## Introduction au projet\n",
    "\n",
    "Il s'agit dans ce projet d'utiliser des données cartographiques décrivant des carrées de 30m x 30m pour construire un modèle prédictif de l'espèce d'arbre présente sur un tel carré.\n",
    "\n",
    "Le but final est d'appliquer ce modèle pour faire des prédictions pour des données pour lesquelles vous ne disposez pas d'une étiquette.\n",
    "\n",
    "__Consignes :__ \n",
    "* Vous devez rendre, par binôme :\n",
    "    * un notebook jupyter\n",
    "    * un fichier de prédictions (voir plus bas pour le format)\n",
    "* __Renseignez vos noms/prénoms__ dans le titre du notebook\n",
    "* Vous avez jusqu'au __1er juillet midi heure de Paris__\n",
    "* Déposez vos fichiers [sur Campus](https://campus.mines-paristech.fr/course/view.php?id=404) dans la section dédiée (un seul rendu par binôme est nécessaire)\n",
    "\n",
    "\n",
    "__Déroulé :__\n",
    "* Les séances du lundi 14/06 (15h30-17h) et jeudi 24/06 (15h30-17h) sont dédiées au projet numérique. Faites-en bon usage.\n",
    "* Certaines sections font appel à des notions qui n'auront pas encore été vues le 14/06 ; c'est indiqué le cas échéant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdee30fc-75fc-4e62-8070-6a2a8fff2f27",
   "metadata": {},
   "source": [
    "## Données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd5ed63-af4d-4e79-bf38-f28dce55717e",
   "metadata": {},
   "source": [
    "### Données publiques et privées\n",
    "\n",
    "Le dossier `data/` contient deux jeux de données :\n",
    "* `data/foret_public.tsv` contient les données étiquetées, à partir desquelles construire votre modèle\n",
    "* `data/foret_prive.tsv` contient les données non-étiquetées, pour lesquelles faire vos prédictions.\n",
    "\n",
    "Chaque ligne dans les données correspond à un carré de 30 m x 30m, décrit par les variables suivantes :\n",
    "* `altitude` : altitude en mètres\n",
    "* `exposition` : azimut en degrés \n",
    "* `pente` : pente en degrés\n",
    "* `distance_horizontale_hydro` : distance horizontale au point d'eau le plus proche (en mètres)\n",
    "* `distance_verticale_hydro` : distance verticale au point d'eau le plus proche (en mètres)\n",
    "* `distance_horizontale_route` : distance horizontale à la route la plus proche (en mètres)\n",
    "* `ombrage_0900` : index d'ombrages à 9h du matin, au solstice, sur une échelle de 0 à 255\n",
    "* `ombrage_1200` : index d'ombrages à midi, au solstice, sur une échelle de 0 à 255\n",
    "* `ombrage_1500` : index d'ombrages à 15h, au solstice, sur une échelle de 0 à 255\n",
    "* `distance_horizontale_depart_feu` : distance horizontale au départ de feu de forêt le plus proche (en mètres)\n",
    "* `espece` : étiquette : espèce d'arbre présente (0 = pin tordu ; 1 = peuplier)|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda94d36-60a1-415f-adfb-a3366bc4b292",
   "metadata": {},
   "source": [
    "### Chargement des données étiquetées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d75dc6be-91ac-4a26-b40c-a74523e2adf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b53d281b-c6a6-42b4-949a-4c732f626837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c1ef8d0-c3e8-4f31-9bf6-bba291ddfc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_public = pd.read_csv('data/foret_public.tsv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d7fbf16-77e0-47a2-8253-004fea627b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>altitude</th>\n",
       "      <th>exposition</th>\n",
       "      <th>pente</th>\n",
       "      <th>distance_horizontale_hydro</th>\n",
       "      <th>distance_verticale_hydro</th>\n",
       "      <th>distance_horizontale_route</th>\n",
       "      <th>ombrage_0900</th>\n",
       "      <th>ombrage_1200</th>\n",
       "      <th>ombrage_1500</th>\n",
       "      <th>distance_horizontale_depart_feu</th>\n",
       "      <th>espece</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2579</td>\n",
       "      <td>132</td>\n",
       "      <td>6</td>\n",
       "      <td>300</td>\n",
       "      <td>-15</td>\n",
       "      <td>67</td>\n",
       "      <td>230</td>\n",
       "      <td>237</td>\n",
       "      <td>140</td>\n",
       "      <td>6031</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2886</td>\n",
       "      <td>151</td>\n",
       "      <td>11</td>\n",
       "      <td>371</td>\n",
       "      <td>26</td>\n",
       "      <td>5253</td>\n",
       "      <td>234</td>\n",
       "      <td>240</td>\n",
       "      <td>136</td>\n",
       "      <td>4051</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2742</td>\n",
       "      <td>134</td>\n",
       "      <td>22</td>\n",
       "      <td>150</td>\n",
       "      <td>69</td>\n",
       "      <td>3215</td>\n",
       "      <td>248</td>\n",
       "      <td>224</td>\n",
       "      <td>92</td>\n",
       "      <td>6091</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   altitude  exposition  pente  distance_horizontale_hydro  \\\n",
       "0      2804         139      9                         268   \n",
       "1      2785         155     18                         242   \n",
       "2      2579         132      6                         300   \n",
       "3      2886         151     11                         371   \n",
       "4      2742         134     22                         150   \n",
       "\n",
       "   distance_verticale_hydro  distance_horizontale_route  ombrage_0900  \\\n",
       "0                        65                        3180           234   \n",
       "1                       118                        3090           238   \n",
       "2                       -15                          67           230   \n",
       "3                        26                        5253           234   \n",
       "4                        69                        3215           248   \n",
       "\n",
       "   ombrage_1200  ombrage_1500  distance_horizontale_depart_feu  espece  \n",
       "0           238           135                             6121       0  \n",
       "1           238           122                             6211       0  \n",
       "2           237           140                             6031       0  \n",
       "3           240           136                             4051       0  \n",
       "4           224            92                             6091       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_public.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2e1234-df6f-45ed-9183-8855e9aaf4f1",
   "metadata": {},
   "source": [
    "### Extraction de la matrice de design et des étiquettes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a6eb7b7-9648-4dd2-924b-0a6686e225ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_public = np.array(df_public.drop(columns=[\"espece\"]))\n",
    "y_public = np.array(df_public[\"espece\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "931a0b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>altitude</th>\n",
       "      <th>exposition</th>\n",
       "      <th>pente</th>\n",
       "      <th>distance_horizontale_hydro</th>\n",
       "      <th>distance_verticale_hydro</th>\n",
       "      <th>distance_horizontale_route</th>\n",
       "      <th>ombrage_0900</th>\n",
       "      <th>ombrage_1200</th>\n",
       "      <th>ombrage_1500</th>\n",
       "      <th>distance_horizontale_depart_feu</th>\n",
       "      <th>espece</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2579</td>\n",
       "      <td>132</td>\n",
       "      <td>6</td>\n",
       "      <td>300</td>\n",
       "      <td>-15</td>\n",
       "      <td>67</td>\n",
       "      <td>230</td>\n",
       "      <td>237</td>\n",
       "      <td>140</td>\n",
       "      <td>6031</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2886</td>\n",
       "      <td>151</td>\n",
       "      <td>11</td>\n",
       "      <td>371</td>\n",
       "      <td>26</td>\n",
       "      <td>5253</td>\n",
       "      <td>234</td>\n",
       "      <td>240</td>\n",
       "      <td>136</td>\n",
       "      <td>4051</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2742</td>\n",
       "      <td>134</td>\n",
       "      <td>22</td>\n",
       "      <td>150</td>\n",
       "      <td>69</td>\n",
       "      <td>3215</td>\n",
       "      <td>248</td>\n",
       "      <td>224</td>\n",
       "      <td>92</td>\n",
       "      <td>6091</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>3077</td>\n",
       "      <td>129</td>\n",
       "      <td>3</td>\n",
       "      <td>618</td>\n",
       "      <td>43</td>\n",
       "      <td>6296</td>\n",
       "      <td>225</td>\n",
       "      <td>237</td>\n",
       "      <td>147</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2755</td>\n",
       "      <td>320</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>-1</td>\n",
       "      <td>2890</td>\n",
       "      <td>209</td>\n",
       "      <td>236</td>\n",
       "      <td>165</td>\n",
       "      <td>5468</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2880</td>\n",
       "      <td>86</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>4369</td>\n",
       "      <td>237</td>\n",
       "      <td>221</td>\n",
       "      <td>113</td>\n",
       "      <td>5906</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2827</td>\n",
       "      <td>332</td>\n",
       "      <td>15</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>3599</td>\n",
       "      <td>185</td>\n",
       "      <td>221</td>\n",
       "      <td>174</td>\n",
       "      <td>6067</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2518</td>\n",
       "      <td>107</td>\n",
       "      <td>5</td>\n",
       "      <td>360</td>\n",
       "      <td>39</td>\n",
       "      <td>553</td>\n",
       "      <td>229</td>\n",
       "      <td>234</td>\n",
       "      <td>139</td>\n",
       "      <td>3522</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    altitude  exposition  pente  distance_horizontale_hydro  \\\n",
       "0       2804         139      9                         268   \n",
       "1       2785         155     18                         242   \n",
       "2       2579         132      6                         300   \n",
       "3       2886         151     11                         371   \n",
       "4       2742         134     22                         150   \n",
       "..       ...         ...    ...                         ...   \n",
       "95      3077         129      3                         618   \n",
       "96      2755         320      4                          30   \n",
       "97      2880          86     12                          30   \n",
       "98      2827         332     15                          42   \n",
       "99      2518         107      5                         360   \n",
       "\n",
       "    distance_verticale_hydro  distance_horizontale_route  ombrage_0900  \\\n",
       "0                         65                        3180           234   \n",
       "1                        118                        3090           238   \n",
       "2                        -15                          67           230   \n",
       "3                         26                        5253           234   \n",
       "4                         69                        3215           248   \n",
       "..                       ...                         ...           ...   \n",
       "95                        43                        6296           225   \n",
       "96                        -1                        2890           209   \n",
       "97                         3                        4369           237   \n",
       "98                         9                        3599           185   \n",
       "99                        39                         553           229   \n",
       "\n",
       "    ombrage_1200  ombrage_1500  distance_horizontale_depart_feu  espece  \n",
       "0            238           135                             6121       0  \n",
       "1            238           122                             6211       0  \n",
       "2            237           140                             6031       0  \n",
       "3            240           136                             4051       0  \n",
       "4            224            92                             6091       0  \n",
       "..           ...           ...                              ...     ...  \n",
       "95           237           147                             3261       0  \n",
       "96           236           165                             5468       0  \n",
       "97           221           113                             5906       0  \n",
       "98           221           174                             6067       0  \n",
       "99           234           139                             3522       0  \n",
       "\n",
       "[100 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_public.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2097f148-8f09-4447-b6f4-a53fac8e4597",
   "metadata": {},
   "source": [
    "### Visualisation des variables\n",
    "\n",
    "#### Question 1\n",
    "Visualisez chacune des variables de `X_public` sous la forme de deux histogrammes superposés, l'un correspondant aux observations de la classe positive, l'autre correspondant aux observations de la classe négative.\n",
    "\n",
    "__Conseils :__\n",
    "* utilisez `pos_indices = np.where(y_public==1)[0]` pour déterminer les indices des lignes de `y_public` (et donc dans `X_public`) dont l'étiquette vaut 0.\n",
    "* utilisez l'argument `alpha` de `plt.hist` pour rendre vos histogrammes transparents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc0b08a-e621-49b7-bbc5-566ab210d992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(X_public, title=\"\"):  \n",
    "    \"\"\"\n",
    "        Retourne, pour chacune des variables de df_public, deux histogrammes superposés, l'un pour la classe positive et l'autre pour la classe négative\n",
    "    \"\"\"\n",
    "    \n",
    "    features = list(df_public.drop(columns=['espece']).columns) # Noms des colonnes\n",
    "    \n",
    "    X_public_pos = X_public[np.where(y_public==1)[0]] # Lignes correspondant à des peupliers\n",
    "    X_public_neg = X_public[np.where(y_public==0)[0]] # Lignes correspondant à des pins tordus\n",
    "    \n",
    "    features_idx = [features.index(feat_name) for feat_name in features] # indices des colonnes\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # Histograms for continuous features\n",
    "    for plot_idx, feat_idx in enumerate(features_idx):\n",
    "        \n",
    "        # create a subplot in the (plot_idx+1) position of a 2x2 grid\n",
    "        ax = fig.add_subplot(5, 2, (plot_idx+1))\n",
    "        # plot the histograms of feat_idx\n",
    "        h1 = ax.hist(X_public_pos[feat_idx], bins=30, edgecolor='none', alpha=0.2, label=\"peupliers\")\n",
    "        h2 = ax.hist(X_public_neg[feat_idx], bins=30, edgecolor='none', alpha=0.2, label=\"pins tordus\")\n",
    "        # use the name of the feature as a title for each histogram\n",
    "        ax.set_title(features[feat_idx])\n",
    "        if plot_idx == 0:\n",
    "            fig.legend(loc='upper right', bbox_to_anchor=(0, 1))\n",
    "            \n",
    "    fig.tight_layout(pad=1.0)\n",
    "    fig.suptitle(\"Histogrammes pour chaque variable des classes positive et négative \" + title, y=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c50b77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(X_public)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1aa716-c22d-4710-8f03-1ee2d60b8aba",
   "metadata": {},
   "source": [
    "#### Question 2\n",
    "Pensez-vous qu'il va être aisé de distinguer les deux classes ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-white",
   "metadata": {},
   "source": [
    "*A priori, on ne distingue pas de critères simples permettant de classer les arbres suivant leur espèce. En effet, on observe des zones de recouvrement entre les deux espèces pour la plupart des paramètres.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a88a2e-5928-43e8-b2f3-d574e76a6ddd",
   "metadata": {},
   "source": [
    "### Pré-traitement des variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c589d4-631e-44c6-9c96-b6b3a0db4466",
   "metadata": {},
   "source": [
    "#### Question 3\n",
    "Transformez vos variables d'une manière qui vous parait judicieuse, en vous appuyant notamment sur la PC 3. Vous pouvez essayer différents pré-traitements, mais ce n'est pas nécessaire. Justifiez vos choix. Utilisez un array numpy `X_public_preprocessed` pour enregistrer le résultat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a45cf01-4000-40b8-8e8b-298d01f61156",
   "metadata": {
    "tags": [
     "level_basic"
    ]
   },
   "outputs": [],
   "source": [
    "# Yeo-Johnson\n",
    "yj_scaler = preprocessing.PowerTransformer(method='yeo-johnson')\n",
    "yj_scaler.fit(X_public)\n",
    "X_public_preprocessed = yj_scaler.transform(X_public)\n",
    "\n",
    "# Standard Scaler\n",
    "s_scaler = preprocessing.StandardScaler()\n",
    "s_scaler.fit(X_public)\n",
    "X_public_preprocessed_s = s_scaler.transform(X_public)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56c5b4b",
   "metadata": {},
   "source": [
    "*On peut tout d'abord centrer et réduire les données, afin que les différentes grandeurs soient comparables, à l'aide de la classe StandardScaler.*\n",
    "\n",
    "*Une autre idée serait de réaliser un prétraitement non-linéaire des données, prenant en compte l'asymétrie des données.*\n",
    "\n",
    "*Cependant, la méthode Box-Cox vue en cours ne tolère pas les valeurs négatives. On utilise donc la méthode Yeo-Johnson, qui est également une transformation normale mais supportant les valeurs négatives.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f7be10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# affichage\n",
    "plot_hist(X_public_preprocessed, \"(Yeo-Johnson)\")\n",
    "plot_hist(X_public_preprocessed_s, \"(normalisation standard)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e3af5e",
   "metadata": {},
   "source": [
    "*On observe bien des données mieux réparties et normalisées, avec toujours des phénomènes de recouvrement.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb82bf83-2130-4d0f-98d1-49faa8578d3d",
   "metadata": {},
   "source": [
    "## Premier modèle : 5-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac6e657-3b8f-4576-b192-119cea1a65ef",
   "metadata": {},
   "source": [
    "### Algorithme des k plus proches voisins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05c88df-2666-44f9-8c5d-067e32238a82",
   "metadata": {},
   "source": [
    "Nous n'avons pas encore vu d'algorithme permettant d'entraîner un modèle de classification. Nous allons donc commencer avec un modèle simple : celui des __k plus proches voisins__ (ou __kNN__, pour _k nearest neighbors_).\n",
    "\n",
    "Dans ce modèle, la valeur de la fonction de décision en x est la proportion d'individus d'étiquette positive parmi les k plus proches voisins de x au sein des points du jeu d'entraînement ; k est fixé."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f093f4a-6905-4404-9a34-4aa3e0b70bcf",
   "metadata": {},
   "source": [
    "Nous allons commencer par utiliser un algorithme des k plus proches voisins avec k fixé à k=5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9ac02f-3035-47a7-8a75-9ebd604ffae9",
   "metadata": {},
   "source": [
    "#### Question 4\n",
    "\n",
    "Entraînez un modèle des sur les données `(X_public_preprocessed, y_public)` grâce à la classe `KNeighborsClassifier` du module `neighbors` de `sklearn`, utilisez l'algorithme des 5 plus proches voisins pour entrainer un modèle sur votre jeu d'entraînement.\n",
    "\n",
    "Documentation https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747297ef-4a20-4e9f-af49-f9188f0e6027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837e1249",
   "metadata": {},
   "source": [
    "*D'après la documentation, on écrit le code suivant :*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d51ed84-98b2-4ac7-84a4-d21f2b652b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = neighbors.KNeighborsClassifier(n_neighbors=5) \n",
    "neigh.fit(X_public_preprocessed, y_public)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b34345-fa60-47de-904f-e44e655e9ccd",
   "metadata": {},
   "source": [
    "### Performance\n",
    "\n",
    "Il existe de nombreuses métriques pour évaluer les performances d'un algorithme de classification. Nous allons ici utiliser le F-score, dont vous trouverez une description dans la documentation du module `metrics` de `sklearn` : https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score et https://scikit-learn.org/stable/modules/model_evaluation.html#precision-recall-f-measure-metrics.\n",
    "\n",
    "#### Question 5\n",
    "Quel serait sur nos données le F-score d'un modèle naïf prédisant systématiquement la classe positive ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5576271c",
   "metadata": {},
   "source": [
    "*On utilise le mode 'binary' car on est face à un problème de classification binaire.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d9d47d-947b-4151-9481-25d8a462877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_public, [1]*len(y_public), average='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e714ed",
   "metadata": {},
   "source": [
    "*On obtient environ 0.67, on s'attend par la suite à un F-score plus proche de 1.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c608f7e-e309-4127-9011-7e906000dadc",
   "metadata": {},
   "source": [
    "#### Question 6\n",
    "\n",
    "Quelle est le F-score du modèle de 5 plus proches voisins que vous venez d'entraîner, sur les données `(X_public_preprocessed, y_public)` ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a00a75f3-2767-41c2-8b49-e4287897c9d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9276089000313382"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = neigh.predict(X_public_preprocessed)\n",
    "f1_score(y_public, y_pred, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "747dd16a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9290079924776682"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Résultat pour le preprossing StandardScaler\n",
    "\n",
    "neigh_s = neighbors.KNeighborsClassifier(n_neighbors=5) \n",
    "neigh_s.fit(X_public_preprocessed_s, y_public)\n",
    "y_pred = neigh_s.predict(X_public_preprocessed_s)\n",
    "f1_score(y_public, y_pred, average='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52abbfb2",
   "metadata": {},
   "source": [
    "*On observe des performances comparables pour les différents prétraitements.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c1d437-e850-40b2-ae6d-aeeedb1090ce",
   "metadata": {},
   "source": [
    "#### Question 7\n",
    "* Que pensez-vous de cette performance ? \n",
    "* Est-ce une bonne idée d'évaluer le modèle sur le jeu d'entraînement ? (Réfléchissez en particulier au cas où k=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c99114",
   "metadata": {},
   "source": [
    "*La performance est bonne, meilleure que l'aléatoire. Elle peut cependant être améliorée assez facilement, par exemple en utilisant un mode de pondération différent (distance, qui donne un F-score de 1 sur ces données avec le prétraitement Yeo-Johnson).*\n",
    "\n",
    "*Cette performance peut s'expliquer par un phénomène de surapprentissage, qui est d'autant plus marqué que $k$ est faible. Ainsi, dans le cas $k=1$, on assiste à un apprentissage par coeur. Ce dernier donne ici de très bons résultats (F-score de 1), mais cela est dû au fait que le modèle est testé sur le jeu d'entrainement (cf cellule ci-dessous).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19e045aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcul du F-score avec k=1, prétraitement Yeo-Johnson (apprentissage par coeur)\n",
    "\n",
    "neigh = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "neigh.fit(X_public_preprocessed, y_public)\n",
    "y_pred = neigh.predict(X_public_preprocessed)\n",
    "f1_score(y_public, y_pred, average='binary') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3d729e-53f6-48ed-991b-f9f0f6673f94",
   "metadata": {},
   "source": [
    "## Création d'un jeu de test\n",
    "\n",
    "À partir de maintenant, nous allons séparer les données en un jeu d'entraînement, que nous utiliserons pour entraîner différents modèles, et un jeu de test, que nous utiliserons pour les comparer. (Cf CM 8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00908d3c-3d44-48a6-b408-0ed2e78de0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47ce3a28-dfc8-4023-abdf-f7ad1c4227d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Use 20% for testing\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X_public, y_public, test_size=0.20,\n",
    "                                                                    stratify=y_public,\n",
    "                                                                    random_state=42) \n",
    "X_train.shape, X_test.shape\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a54a89",
   "metadata": {},
   "source": [
    "*On normalise les jeux d'entrainement et de test par les mêmes méthodes que précédemment.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0637ac77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Florent\\.conda\\envs\\sdd2021\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:3237: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    }
   ],
   "source": [
    "# Jeux d'entrainement avec Yeo-Johnson\n",
    "yj_scaler = preprocessing.PowerTransformer(method='yeo-johnson')\n",
    "yj_scaler.fit(X_train)\n",
    "X_train_preprocessed = yj_scaler.transform(X_train)\n",
    "X_test_preprocessed = yj_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8d23305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jeux d'entrainement avec le StandardScaler\n",
    "s_scaler = preprocessing.StandardScaler()\n",
    "s_scaler.fit(X_train)\n",
    "X_train_preprocessed_s = s_scaler.transform(X_train)\n",
    "X_test_preprocessed_s = s_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cf00af-77f5-4051-a05a-ab9432b228a0",
   "metadata": {},
   "source": [
    "### Performance sur le jeu de test d'un 5-NN entraîné sur le jeu d'entrainement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44f1211-a214-47a5-a709-0590c9dd01a8",
   "metadata": {},
   "source": [
    "#### Question 8.a \n",
    "\n",
    "Entrainez de nouveau un modèle avec l'algorithme des 5 plus proches voisins, mais cette fois, utilisez uniquement le jeu d'entraînement. __Attention__ à bien « entraîner » votre pre-processing sur le jeu d'entraînement seulement ; considérez le jeu de test comme des données que vous ne voyez pas au moment de l'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa168ef9-edb0-4f8a-9f66-6b745b1b5709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrainement sur le jeu d'entrainement\n",
    "neigh_train = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "neigh_train.fit(X_train_preprocessed, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7499da0b-24f7-4e9a-8b67-f9aa05005aa1",
   "metadata": {},
   "source": [
    "#### Question 8.b\n",
    "Évaluez le F-score sur le jeu de test du modèle entraîné à la question précédente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d453b21-9ff3-4cf7-b6a7-75a74bf7eaff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8630769230769231"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pour le Yeo-Johnson\n",
    "\n",
    "y_pred = neigh_train.predict(X_test_preprocessed)\n",
    "f1_score(y_test, y_pred, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d59f4854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8956587966488957"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Valeur pour le StandardScaler\n",
    "neigh_train_s = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "neigh_train_s.fit(X_train_preprocessed_s, y_train)\n",
    "y_pred = neigh_train_s.predict(X_test_preprocessed_s)\n",
    "f1_score(y_test, y_pred, average='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b89cae6",
   "metadata": {},
   "source": [
    "*On observe que le résultat est meilleur avec le prétraitement de StandardScaler.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9beee624-9828-4c0a-8f1f-1930df57d9fb",
   "metadata": {},
   "source": [
    "#### Question 9\n",
    "Commentez le F-score obtenu ci-dessus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad29ae27",
   "metadata": {},
   "source": [
    "*Dans les deux cas, le F-score calculé est inférieur à celui obtenu précédemment. En effet, le phénomène de surapprentissage, qui n'est plus possible avec les données de test, gonflait artificiellement le F-score. Si la note obtenue est inférieure, elle est néanmoins plus représentative des performances réelles du modèle.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "978a60e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def f_score(k=5, weights=\"uniform\", x_test = X_test_preprocessed, x_train = X_train_preprocessed):\n",
    "    \"\"\"\n",
    "    Calcule le F-score pour les paramètres passés en arguments avec le modèle kNN\n",
    "    \"\"\"\n",
    "    neigh_train = neighbors.KNeighborsClassifier(n_neighbors=k, weights=weights)\n",
    "    neigh_train.fit(x_train, y_train)\n",
    "    y_pred = neigh_train.predict(x_test)\n",
    "    return f1_score(y_test, y_pred, average='binary')\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "idx = [2*i+1 for i in range(1, 15)]\n",
    "pts = []\n",
    "pts_dist = []\n",
    "for k in idx:        \n",
    "    pts.append(f_score(k))  \n",
    "    pts_dist.append(f_score(k, \"distance\"))\n",
    "\n",
    "plt.plot(idx, pts, label=\"distance\")\n",
    "plt.plot(idx, pts_dist, label=\"uniform\")\n",
    "plt.legend();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6405b44-a6fe-4c66-b49d-7abef561b6cc",
   "metadata": {},
   "source": [
    "## [À partir du CM 8 / de la PC 4] Sélection du nombre de plus proches voisins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d956186-5bbc-461f-af32-96e0d25988d2",
   "metadata": {},
   "source": [
    "#### Question 10.a \n",
    "Utilisez maintenant une validation croisée pour sélectionner la valeur optimale du nombre de voisins avec `GridSearchCV` (voir notamment PC4). \n",
    "\n",
    "Vous pouvez utiliser la grille de valeurs de k suivante, ou la modifier :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16f3d578-78c0-43cc-a3eb-12b67de43810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres testés\n",
    "n_neighbors = np.arange(1, 15, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "25507e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "[CV 1/5] END .....................n_neighbors=1;, score=0.864 total time=   0.0s\n",
      "[CV 2/5] END .....................n_neighbors=1;, score=0.863 total time=   0.1s\n",
      "[CV 3/5] END .....................n_neighbors=1;, score=0.858 total time=   0.0s\n",
      "[CV 4/5] END .....................n_neighbors=1;, score=0.855 total time=   0.1s\n",
      "[CV 5/5] END .....................n_neighbors=1;, score=0.873 total time=   0.0s\n",
      "[CV 1/5] END .....................n_neighbors=2;, score=0.848 total time=   0.0s\n",
      "[CV 2/5] END .....................n_neighbors=2;, score=0.834 total time=   0.0s\n",
      "[CV 3/5] END .....................n_neighbors=2;, score=0.834 total time=   0.1s\n",
      "[CV 4/5] END .....................n_neighbors=2;, score=0.831 total time=   0.0s\n",
      "[CV 5/5] END .....................n_neighbors=2;, score=0.852 total time=   0.0s\n",
      "[CV 1/5] END .....................n_neighbors=3;, score=0.872 total time=   0.0s\n",
      "[CV 2/5] END .....................n_neighbors=3;, score=0.873 total time=   0.1s\n",
      "[CV 3/5] END .....................n_neighbors=3;, score=0.856 total time=   0.0s\n",
      "[CV 4/5] END .....................n_neighbors=3;, score=0.841 total time=   0.1s\n",
      "[CV 5/5] END .....................n_neighbors=3;, score=0.876 total time=   0.0s\n",
      "[CV 1/5] END .....................n_neighbors=4;, score=0.861 total time=   0.0s\n",
      "[CV 2/5] END .....................n_neighbors=4;, score=0.865 total time=   0.0s\n",
      "[CV 3/5] END .....................n_neighbors=4;, score=0.847 total time=   0.1s\n",
      "[CV 4/5] END .....................n_neighbors=4;, score=0.839 total time=   0.1s\n",
      "[CV 5/5] END .....................n_neighbors=4;, score=0.868 total time=   0.1s\n",
      "[CV 1/5] END .....................n_neighbors=5;, score=0.868 total time=   0.1s\n",
      "[CV 2/5] END .....................n_neighbors=5;, score=0.856 total time=   0.1s\n",
      "[CV 3/5] END .....................n_neighbors=5;, score=0.847 total time=   0.1s\n",
      "[CV 4/5] END .....................n_neighbors=5;, score=0.841 total time=   0.2s\n",
      "[CV 5/5] END .....................n_neighbors=5;, score=0.862 total time=   0.0s\n",
      "[CV 1/5] END .....................n_neighbors=6;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END .....................n_neighbors=6;, score=0.857 total time=   0.1s\n",
      "[CV 3/5] END .....................n_neighbors=6;, score=0.844 total time=   0.1s\n",
      "[CV 4/5] END .....................n_neighbors=6;, score=0.834 total time=   0.3s\n",
      "[CV 5/5] END .....................n_neighbors=6;, score=0.854 total time=   0.1s\n",
      "[CV 1/5] END .....................n_neighbors=7;, score=0.861 total time=   0.1s\n",
      "[CV 2/5] END .....................n_neighbors=7;, score=0.850 total time=   0.1s\n",
      "[CV 3/5] END .....................n_neighbors=7;, score=0.842 total time=   0.1s\n",
      "[CV 4/5] END .....................n_neighbors=7;, score=0.846 total time=   0.0s\n",
      "[CV 5/5] END .....................n_neighbors=7;, score=0.856 total time=   0.0s\n",
      "[CV 1/5] END .....................n_neighbors=8;, score=0.861 total time=   0.2s\n",
      "[CV 2/5] END .....................n_neighbors=8;, score=0.853 total time=   0.2s\n",
      "[CV 3/5] END .....................n_neighbors=8;, score=0.839 total time=   0.0s\n",
      "[CV 4/5] END .....................n_neighbors=8;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END .....................n_neighbors=8;, score=0.853 total time=   0.1s\n",
      "[CV 1/5] END .....................n_neighbors=9;, score=0.852 total time=   0.2s\n",
      "[CV 2/5] END .....................n_neighbors=9;, score=0.843 total time=   0.1s\n",
      "[CV 3/5] END .....................n_neighbors=9;, score=0.834 total time=   0.1s\n",
      "[CV 4/5] END .....................n_neighbors=9;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END .....................n_neighbors=9;, score=0.844 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=10;, score=0.848 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=10;, score=0.842 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=10;, score=0.837 total time=   0.3s\n",
      "[CV 4/5] END ....................n_neighbors=10;, score=0.823 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=10;, score=0.848 total time=   0.0s\n",
      "[CV 1/5] END ....................n_neighbors=11;, score=0.847 total time=   0.2s\n",
      "[CV 2/5] END ....................n_neighbors=11;, score=0.832 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=11;, score=0.835 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=11;, score=0.825 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=11;, score=0.845 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=12;, score=0.848 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=12;, score=0.827 total time=   0.0s\n",
      "[CV 3/5] END ....................n_neighbors=12;, score=0.835 total time=   0.0s\n",
      "[CV 4/5] END ....................n_neighbors=12;, score=0.821 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=12;, score=0.848 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=13;, score=0.843 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=13;, score=0.835 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=13;, score=0.835 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=13;, score=0.831 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=13;, score=0.847 total time=   0.1s\n",
      "[CV 1/5] END ....................n_neighbors=14;, score=0.835 total time=   0.1s\n",
      "[CV 2/5] END ....................n_neighbors=14;, score=0.832 total time=   0.1s\n",
      "[CV 3/5] END ....................n_neighbors=14;, score=0.832 total time=   0.1s\n",
      "[CV 4/5] END ....................n_neighbors=14;, score=0.812 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=14;, score=0.844 total time=   0.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid=[{'n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])}],\n",
       "             scoring='f1', verbose=3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Validation croisée\n",
    "kneighbors_model = neighbors.KNeighborsClassifier()\n",
    "tuned_parameters = [{'n_neighbors': n_neighbors}]\n",
    "nb_folds = 5\n",
    "grid = GridSearchCV(kneighbors_model, tuned_parameters, cv=nb_folds, refit=True, verbose=3, scoring='f1')\n",
    "grid.fit(X_train_preprocessed, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef9a205-e9a3-47d8-b625-cd68473479f3",
   "metadata": {},
   "source": [
    "#### Question 10.b\n",
    "Quel est le F-score correspondant au nombre de voisin optimal ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "886a46e6-eda1-4f07-a8ae-00f1e8b77541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k 3\n",
      "F-score 0.8635888371024347\n"
     ]
    }
   ],
   "source": [
    "# Pour le Yeo-Johnson\n",
    "\n",
    "k_opti = grid.best_params_['n_neighbors']\n",
    "f_max = grid.best_score_\n",
    "print(\"k\", k_opti)\n",
    "print(\"F-score\", f_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "889fb8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "[CV 1/5] END .....................n_neighbors=1;, score=0.883 total time=   0.0s\n",
      "[CV 2/5] END .....................n_neighbors=1;, score=0.909 total time=   0.1s\n",
      "[CV 3/5] END .....................n_neighbors=1;, score=0.906 total time=   0.0s\n",
      "[CV 4/5] END .....................n_neighbors=1;, score=0.886 total time=   0.0s\n",
      "[CV 5/5] END .....................n_neighbors=1;, score=0.911 total time=   0.0s\n",
      "[CV 1/5] END .....................n_neighbors=2;, score=0.883 total time=   0.0s\n",
      "[CV 2/5] END .....................n_neighbors=2;, score=0.894 total time=   0.0s\n",
      "[CV 3/5] END .....................n_neighbors=2;, score=0.898 total time=   0.0s\n",
      "[CV 4/5] END .....................n_neighbors=2;, score=0.871 total time=   0.0s\n",
      "[CV 5/5] END .....................n_neighbors=2;, score=0.905 total time=   0.0s\n",
      "[CV 1/5] END .....................n_neighbors=3;, score=0.898 total time=   0.0s\n",
      "[CV 2/5] END .....................n_neighbors=3;, score=0.901 total time=   0.0s\n",
      "[CV 3/5] END .....................n_neighbors=3;, score=0.890 total time=   0.0s\n",
      "[CV 4/5] END .....................n_neighbors=3;, score=0.883 total time=   0.0s\n",
      "[CV 5/5] END .....................n_neighbors=3;, score=0.909 total time=   0.0s\n",
      "[CV 1/5] END .....................n_neighbors=4;, score=0.903 total time=   0.0s\n",
      "[CV 2/5] END .....................n_neighbors=4;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END .....................n_neighbors=4;, score=0.886 total time=   0.0s\n",
      "[CV 4/5] END .....................n_neighbors=4;, score=0.875 total time=   0.0s\n",
      "[CV 5/5] END .....................n_neighbors=4;, score=0.907 total time=   0.0s\n",
      "[CV 1/5] END .....................n_neighbors=5;, score=0.893 total time=   0.1s\n",
      "[CV 2/5] END .....................n_neighbors=5;, score=0.893 total time=   0.1s\n",
      "[CV 3/5] END .....................n_neighbors=5;, score=0.886 total time=   0.0s\n",
      "[CV 4/5] END .....................n_neighbors=5;, score=0.872 total time=   0.0s\n",
      "[CV 5/5] END .....................n_neighbors=5;, score=0.894 total time=   0.0s\n",
      "[CV 1/5] END .....................n_neighbors=6;, score=0.895 total time=   0.0s\n",
      "[CV 2/5] END .....................n_neighbors=6;, score=0.894 total time=   0.0s\n",
      "[CV 3/5] END .....................n_neighbors=6;, score=0.883 total time=   0.0s\n",
      "[CV 4/5] END .....................n_neighbors=6;, score=0.865 total time=   0.0s\n",
      "[CV 5/5] END .....................n_neighbors=6;, score=0.897 total time=   0.0s\n",
      "[CV 1/5] END .....................n_neighbors=7;, score=0.889 total time=   0.0s\n",
      "[CV 2/5] END .....................n_neighbors=7;, score=0.887 total time=   0.0s\n",
      "[CV 3/5] END .....................n_neighbors=7;, score=0.879 total time=   0.0s\n",
      "[CV 4/5] END .....................n_neighbors=7;, score=0.860 total time=   0.0s\n",
      "[CV 5/5] END .....................n_neighbors=7;, score=0.892 total time=   0.0s\n",
      "[CV 1/5] END .....................n_neighbors=8;, score=0.891 total time=   0.0s\n",
      "[CV 2/5] END .....................n_neighbors=8;, score=0.887 total time=   0.0s\n",
      "[CV 3/5] END .....................n_neighbors=8;, score=0.878 total time=   0.0s\n",
      "[CV 4/5] END .....................n_neighbors=8;, score=0.863 total time=   0.0s\n",
      "[CV 5/5] END .....................n_neighbors=8;, score=0.892 total time=   0.1s\n",
      "[CV 1/5] END .....................n_neighbors=9;, score=0.880 total time=   0.0s\n",
      "[CV 2/5] END .....................n_neighbors=9;, score=0.878 total time=   0.0s\n",
      "[CV 3/5] END .....................n_neighbors=9;, score=0.871 total time=   0.0s\n",
      "[CV 4/5] END .....................n_neighbors=9;, score=0.861 total time=   0.0s\n",
      "[CV 5/5] END .....................n_neighbors=9;, score=0.878 total time=   0.0s\n",
      "[CV 1/5] END ....................n_neighbors=10;, score=0.882 total time=   0.0s\n",
      "[CV 2/5] END ....................n_neighbors=10;, score=0.886 total time=   0.0s\n",
      "[CV 3/5] END ....................n_neighbors=10;, score=0.872 total time=   0.0s\n",
      "[CV 4/5] END ....................n_neighbors=10;, score=0.863 total time=   0.0s\n",
      "[CV 5/5] END ....................n_neighbors=10;, score=0.885 total time=   0.0s\n",
      "[CV 1/5] END ....................n_neighbors=11;, score=0.870 total time=   0.0s\n",
      "[CV 2/5] END ....................n_neighbors=11;, score=0.876 total time=   0.0s\n",
      "[CV 3/5] END ....................n_neighbors=11;, score=0.868 total time=   0.0s\n",
      "[CV 4/5] END ....................n_neighbors=11;, score=0.860 total time=   0.1s\n",
      "[CV 5/5] END ....................n_neighbors=11;, score=0.878 total time=   0.0s\n",
      "[CV 1/5] END ....................n_neighbors=12;, score=0.873 total time=   0.0s\n",
      "[CV 2/5] END ....................n_neighbors=12;, score=0.881 total time=   0.0s\n",
      "[CV 3/5] END ....................n_neighbors=12;, score=0.871 total time=   0.0s\n",
      "[CV 4/5] END ....................n_neighbors=12;, score=0.865 total time=   0.0s\n",
      "[CV 5/5] END ....................n_neighbors=12;, score=0.886 total time=   0.0s\n",
      "[CV 1/5] END ....................n_neighbors=13;, score=0.871 total time=   0.0s\n",
      "[CV 2/5] END ....................n_neighbors=13;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END ....................n_neighbors=13;, score=0.867 total time=   0.0s\n",
      "[CV 4/5] END ....................n_neighbors=13;, score=0.855 total time=   0.0s\n",
      "[CV 5/5] END ....................n_neighbors=13;, score=0.881 total time=   0.0s\n",
      "[CV 1/5] END ....................n_neighbors=14;, score=0.869 total time=   0.0s\n",
      "[CV 2/5] END ....................n_neighbors=14;, score=0.884 total time=   0.0s\n",
      "[CV 3/5] END ....................n_neighbors=14;, score=0.870 total time=   0.0s\n",
      "[CV 4/5] END ....................n_neighbors=14;, score=0.860 total time=   0.0s\n",
      "[CV 5/5] END ....................n_neighbors=14;, score=0.884 total time=   0.0s\n",
      "k 1\n",
      "f_max 0.8992082788895678\n"
     ]
    }
   ],
   "source": [
    "# pour le preprocessing StandardScaler\n",
    "\n",
    "kneighbors_model = neighbors.KNeighborsClassifier()\n",
    "tuned_parameters = [{'n_neighbors': n_neighbors}]\n",
    "nb_folds = 5\n",
    "grid_s = GridSearchCV(kneighbors_model, tuned_parameters, cv=nb_folds, refit=True, verbose=3, scoring='f1')\n",
    "grid_s.fit(X_train_preprocessed_s, y_train)\n",
    "k_opti = grid_s.best_params_['n_neighbors']\n",
    "f_max = grid_s.best_score_\n",
    "print(\"k\", k_opti)\n",
    "print(\"f_max\", f_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdcc7bb",
   "metadata": {},
   "source": [
    "*Le prétraitement StandardScaler donne toujours de meilleurs résultats que Yeo-Johnson.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338daf11-91b5-4dec-86c9-e5e9029c3215",
   "metadata": {},
   "source": [
    "#### Question 10.c\n",
    "\n",
    "Quel est le F-score, sur le jeu de test, d'un modèle obtenu en entraînant un algorithme des k plus proches voisins, avec le k que vous venez de déterminer, sur le jeu d'entraînement ? Commentez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "429bacda-f440-4f39-b5ac-ca5b9e2f8732",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeu d'entrainement 0.9301128489408037\n",
      "Jeu de test 0.8717156105100463\n"
     ]
    }
   ],
   "source": [
    "# Pour le Yeo-Johnson\n",
    "\n",
    "esti = grid.best_estimator_\n",
    "y_pred_train = esti.predict(X_train_preprocessed)\n",
    "y_pred_test = esti.predict(X_test_preprocessed)\n",
    "print(\"Jeu d'entrainement\", f1_score(y_train, y_pred_train, average='binary'))\n",
    "print(\"Jeu de test\", f1_score(y_test, y_pred_test, average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "eb5194ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeu d'entrainement 1.0\n",
      "Jeu de test 0.9138339920948617\n"
     ]
    }
   ],
   "source": [
    "# Pour le StandardScaler\n",
    "\n",
    "esti_s = grid_s.best_estimator_\n",
    "y_pred_train_s = esti_s.predict(X_train_preprocessed_s)\n",
    "y_pred_test_s = esti_s.predict(X_test_preprocessed_s)\n",
    "print(\"Jeu d'entrainement\", f1_score(y_train, y_pred_train_s, average='binary'))\n",
    "print(\"Jeu de test\", f1_score(y_test, y_pred_test_s, average='binary'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e088a5",
   "metadata": {},
   "source": [
    "Quel que soit le preprocessing, on n'observe pas de variations significatives de la performance entre les performances sur le jeu de test et la moyenne calculée lors de la validation croisée. Toutefois, et à nouveau quel que soit le prétraitement, on observe un surapprentissage sur le jeu d'entrainement en entier.\n",
    "\n",
    "On remarque que les modèles se comportent mieux avec peu de voisins. Cependant, malgré un bon F-score, cela pose la question de la pertinence d'une vision continue de la répartition des espèces, qui est l'intuition sur laquelle repose le modèle des plus proches voisins (encore plus lorsque l'on choisit comme pondération la distance). En effet, la meilleure prédiction est obtenue lorsque l'on ne tient compte que du plus proche voisin ce qui souligne le caractère erratique de la répartition forestière."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a42476-6aff-42a0-91f8-5769bcaab49e",
   "metadata": {},
   "source": [
    "## [À partir de la PC 5] Régression logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327cd4c2-b134-49e9-83ae-532ec909e97f",
   "metadata": {},
   "source": [
    "### Régression logistique non-régularisée"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c0295c-3839-41d8-9005-2fed00d960b3",
   "metadata": {},
   "source": [
    "#### Question 11.a\n",
    "\n",
    "Entraînez une régression logistique non-régularisée sur le jeu d'entraînement.\n",
    "\n",
    "__Conseils :__\n",
    "* Vous trouverez les outils nécessaires dans la classe `LogisticRegression` du module `linear_model` de `scikit-learn` ; il s'agit ainsi d'une variante de la PC5. Comme toujours, référez-vous à la [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
    "* Pour ne pas avoir de régularisation, utilisez `penalty='none'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3edb4e05-3c38-414e-a212-64ac18fef289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(penalty='none')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "\n",
    "# Régression logistique sur le jeu d'entrainement\n",
    "log_reg = LogisticRegression(penalty='none')\n",
    "log_reg.fit(X_train_preprocessed, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151f97c2-a12f-4768-9a24-287ba966264a",
   "metadata": {},
   "source": [
    "#### Question 11.b\n",
    "Évaluez le F-score de cette régression logistique non-régularisée sur le jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f1155783-d782-49d4-b69e-1b1e6512e10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeu d'entrainement 0.7023759899958315\n",
      "Jeu de test 0.7085714285714286\n"
     ]
    }
   ],
   "source": [
    "# Pour le Yeo-Johnson\n",
    "\n",
    "y_pred = log_reg.predict(X_test_preprocessed)\n",
    "print(\"Jeu d'entrainement\", f1_score(y_train, log_reg.predict(X_train_preprocessed), average='binary'))\n",
    "print(\"Jeu de test\", f1_score(y_test, y_pred, average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c7332d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeu d'entrainement 0.7724933086267243\n",
      "Jeu de test 0.7756778964667215\n"
     ]
    }
   ],
   "source": [
    "# Pour le Standard Scaler\n",
    "\n",
    "log_reg_s = LogisticRegression(penalty='none')\n",
    "log_reg_s.fit(X_train_preprocessed_s, y_train)\n",
    "y_pred_s = log_reg_s.predict(X_test_preprocessed_s)\n",
    "print(\"Jeu d'entrainement\", f1_score(y_train, log_reg_s.predict(X_train_preprocessed_s), average='binary'))\n",
    "print(\"Jeu de test\", f1_score(y_test, y_pred_s, average='binary'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b09008-984c-4027-84d9-4bc34bf66e17",
   "metadata": {},
   "source": [
    "#### Question 12\n",
    "Vous attendez-vous à ce qu'utiliser une régularisation l2 améliore les performances du modèle ? Pourquoi ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b68d800",
   "metadata": {},
   "source": [
    "Pour les deux prétraitements, le F-score sur le jeu d'entrainement est plutôt faible et proche de celui du jeu de test, il n'y a donc a priori pas de surapprentissage. Or, la régularisation Ridge a pour but de limiter le surapprentissage. Par conséquent, on ne s'attend pas à une amélioration significative des performances sur le jeu de test par l'ajout d'une régularisation Ridge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f77f9d8-168f-4db4-bd3b-374447ca90d5",
   "metadata": {},
   "source": [
    "#### Question 13.a\n",
    "Déterminez par validation croisée une valeur optimale du coefficient de régularisation d'une régression logistique avec régularisation ridge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "465f5a44-ace6-4819-9c49-38297f60bb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV 1/5] END ..........................C=0.0001;, score=0.651 total time=   0.0s\n",
      "[CV 2/5] END ..........................C=0.0001;, score=0.641 total time=   0.0s\n",
      "[CV 3/5] END ..........................C=0.0001;, score=0.666 total time=   0.0s\n",
      "[CV 4/5] END ..........................C=0.0001;, score=0.657 total time=   0.0s\n",
      "[CV 5/5] END ..........................C=0.0001;, score=0.637 total time=   0.0s\n",
      "[CV 1/5] END ..........C=0.00018873918221350977;, score=0.650 total time=   0.0s\n",
      "[CV 2/5] END ..........C=0.00018873918221350977;, score=0.654 total time=   0.0s\n",
      "[CV 3/5] END ..........C=0.00018873918221350977;, score=0.674 total time=   0.0s\n",
      "[CV 4/5] END ..........C=0.00018873918221350977;, score=0.663 total time=   0.0s\n",
      "[CV 5/5] END ..........C=0.00018873918221350977;, score=0.637 total time=   0.0s\n",
      "[CV 1/5] END ...........C=0.0003562247890262444;, score=0.656 total time=   0.0s\n",
      "[CV 2/5] END ...........C=0.0003562247890262444;, score=0.668 total time=   0.0s\n",
      "[CV 3/5] END ...........C=0.0003562247890262444;, score=0.679 total time=   0.0s\n",
      "[CV 4/5] END ...........C=0.0003562247890262444;, score=0.672 total time=   0.0s\n",
      "[CV 5/5] END ...........C=0.0003562247890262444;, score=0.651 total time=   0.0s\n",
      "[CV 1/5] END ...........C=0.0006723357536499335;, score=0.666 total time=   0.0s\n",
      "[CV 2/5] END ...........C=0.0006723357536499335;, score=0.672 total time=   0.0s\n",
      "[CV 3/5] END ...........C=0.0006723357536499335;, score=0.688 total time=   0.0s\n",
      "[CV 4/5] END ...........C=0.0006723357536499335;, score=0.676 total time=   0.0s\n",
      "[CV 5/5] END ...........C=0.0006723357536499335;, score=0.672 total time=   0.0s\n",
      "[CV 1/5] END ...........C=0.0012689610031679222;, score=0.682 total time=   0.0s\n",
      "[CV 2/5] END ...........C=0.0012689610031679222;, score=0.681 total time=   0.0s\n",
      "[CV 3/5] END ...........C=0.0012689610031679222;, score=0.695 total time=   0.0s\n",
      "[CV 4/5] END ...........C=0.0012689610031679222;, score=0.679 total time=   0.0s\n",
      "[CV 5/5] END ...........C=0.0012689610031679222;, score=0.668 total time=   0.0s\n",
      "[CV 1/5] END ............C=0.002395026619987486;, score=0.693 total time=   0.0s\n",
      "[CV 2/5] END ............C=0.002395026619987486;, score=0.693 total time=   0.0s\n",
      "[CV 3/5] END ............C=0.002395026619987486;, score=0.697 total time=   0.0s\n",
      "[CV 4/5] END ............C=0.002395026619987486;, score=0.687 total time=   0.0s\n",
      "[CV 5/5] END ............C=0.002395026619987486;, score=0.678 total time=   0.0s\n",
      "[CV 1/5] END ............C=0.004520353656360241;, score=0.697 total time=   0.0s\n",
      "[CV 2/5] END ............C=0.004520353656360241;, score=0.698 total time=   0.0s\n",
      "[CV 3/5] END ............C=0.004520353656360241;, score=0.706 total time=   0.0s\n",
      "[CV 4/5] END ............C=0.004520353656360241;, score=0.688 total time=   0.0s\n",
      "[CV 5/5] END ............C=0.004520353656360241;, score=0.688 total time=   0.0s\n",
      "[CV 1/5] END ............C=0.008531678524172805;, score=0.699 total time=   0.0s\n",
      "[CV 2/5] END ............C=0.008531678524172805;, score=0.700 total time=   0.0s\n",
      "[CV 3/5] END ............C=0.008531678524172805;, score=0.703 total time=   0.0s\n",
      "[CV 4/5] END ............C=0.008531678524172805;, score=0.694 total time=   0.0s\n",
      "[CV 5/5] END ............C=0.008531678524172805;, score=0.695 total time=   0.0s\n",
      "[CV 1/5] END .............C=0.01610262027560939;, score=0.700 total time=   0.0s\n",
      "[CV 2/5] END .............C=0.01610262027560939;, score=0.700 total time=   0.0s\n",
      "[CV 3/5] END .............C=0.01610262027560939;, score=0.706 total time=   0.0s\n",
      "[CV 4/5] END .............C=0.01610262027560939;, score=0.698 total time=   0.0s\n",
      "[CV 5/5] END .............C=0.01610262027560939;, score=0.694 total time=   0.0s\n",
      "[CV 1/5] END .............C=0.03039195382313198;, score=0.702 total time=   0.0s\n",
      "[CV 2/5] END .............C=0.03039195382313198;, score=0.696 total time=   0.0s\n",
      "[CV 3/5] END .............C=0.03039195382313198;, score=0.708 total time=   0.0s\n",
      "[CV 4/5] END .............C=0.03039195382313198;, score=0.697 total time=   0.0s\n",
      "[CV 5/5] END .............C=0.03039195382313198;, score=0.693 total time=   0.0s\n",
      "[CV 1/5] END .............C=0.05736152510448681;, score=0.702 total time=   0.0s\n",
      "[CV 2/5] END .............C=0.05736152510448681;, score=0.696 total time=   0.0s\n",
      "[CV 3/5] END .............C=0.05736152510448681;, score=0.711 total time=   0.0s\n",
      "[CV 4/5] END .............C=0.05736152510448681;, score=0.697 total time=   0.0s\n",
      "[CV 5/5] END .............C=0.05736152510448681;, score=0.693 total time=   0.0s\n",
      "[CV 1/5] END ..............C=0.1082636733874054;, score=0.702 total time=   0.0s\n",
      "[CV 2/5] END ..............C=0.1082636733874054;, score=0.695 total time=   0.0s\n",
      "[CV 3/5] END ..............C=0.1082636733874054;, score=0.711 total time=   0.0s\n",
      "[CV 4/5] END ..............C=0.1082636733874054;, score=0.700 total time=   0.0s\n",
      "[CV 5/5] END ..............C=0.1082636733874054;, score=0.692 total time=   0.0s\n",
      "[CV 1/5] END .............C=0.20433597178569418;, score=0.706 total time=   0.0s\n",
      "[CV 2/5] END .............C=0.20433597178569418;, score=0.697 total time=   0.0s\n",
      "[CV 3/5] END .............C=0.20433597178569418;, score=0.709 total time=   0.0s\n",
      "[CV 4/5] END .............C=0.20433597178569418;, score=0.700 total time=   0.0s\n",
      "[CV 5/5] END .............C=0.20433597178569418;, score=0.694 total time=   0.0s\n",
      "[CV 1/5] END .............C=0.38566204211634725;, score=0.706 total time=   0.0s\n",
      "[CV 2/5] END .............C=0.38566204211634725;, score=0.697 total time=   0.0s\n",
      "[CV 3/5] END .............C=0.38566204211634725;, score=0.710 total time=   0.0s\n",
      "[CV 4/5] END .............C=0.38566204211634725;, score=0.701 total time=   0.0s\n",
      "[CV 5/5] END .............C=0.38566204211634725;, score=0.694 total time=   0.0s\n",
      "[CV 1/5] END ..............C=0.7278953843983146;, score=0.703 total time=   0.0s\n",
      "[CV 2/5] END ..............C=0.7278953843983146;, score=0.697 total time=   0.0s\n",
      "[CV 3/5] END ..............C=0.7278953843983146;, score=0.710 total time=   0.0s\n",
      "[CV 4/5] END ..............C=0.7278953843983146;, score=0.700 total time=   0.0s\n",
      "[CV 5/5] END ..............C=0.7278953843983146;, score=0.694 total time=   0.0s\n",
      "[CV 1/5] END ..............C=1.3738237958832638;, score=0.703 total time=   0.0s\n",
      "[CV 2/5] END ..............C=1.3738237958832638;, score=0.697 total time=   0.0s\n",
      "[CV 3/5] END ..............C=1.3738237958832638;, score=0.710 total time=   0.0s\n",
      "[CV 4/5] END ..............C=1.3738237958832638;, score=0.699 total time=   0.0s\n",
      "[CV 5/5] END ..............C=1.3738237958832638;, score=0.694 total time=   0.0s\n",
      "[CV 1/5] END ...............C=2.592943797404667;, score=0.704 total time=   0.0s\n",
      "[CV 2/5] END ...............C=2.592943797404667;, score=0.697 total time=   0.0s\n",
      "[CV 3/5] END ...............C=2.592943797404667;, score=0.710 total time=   0.0s\n",
      "[CV 4/5] END ...............C=2.592943797404667;, score=0.698 total time=   0.0s\n",
      "[CV 5/5] END ...............C=2.592943797404667;, score=0.694 total time=   0.0s\n",
      "[CV 1/5] END ...............C=4.893900918477489;, score=0.704 total time=   0.0s\n",
      "[CV 2/5] END ...............C=4.893900918477489;, score=0.697 total time=   0.0s\n",
      "[CV 3/5] END ...............C=4.893900918477489;, score=0.710 total time=   0.0s\n",
      "[CV 4/5] END ...............C=4.893900918477489;, score=0.698 total time=   0.0s\n",
      "[CV 5/5] END ...............C=4.893900918477489;, score=0.694 total time=   0.0s\n",
      "[CV 1/5] END ...............C=9.236708571873866;, score=0.704 total time=   0.0s\n",
      "[CV 2/5] END ...............C=9.236708571873866;, score=0.697 total time=   0.0s\n",
      "[CV 3/5] END ...............C=9.236708571873866;, score=0.710 total time=   0.0s\n",
      "[CV 4/5] END ...............C=9.236708571873866;, score=0.698 total time=   0.0s\n",
      "[CV 5/5] END ...............C=9.236708571873866;, score=0.694 total time=   0.0s\n",
      "[CV 1/5] END ..............C=17.433288221999874;, score=0.704 total time=   0.0s\n",
      "[CV 2/5] END ..............C=17.433288221999874;, score=0.697 total time=   0.0s\n",
      "[CV 3/5] END ..............C=17.433288221999874;, score=0.710 total time=   0.0s\n",
      "[CV 4/5] END ..............C=17.433288221999874;, score=0.698 total time=   0.0s\n",
      "[CV 5/5] END ..............C=17.433288221999874;, score=0.694 total time=   0.0s\n",
      "[CV 1/5] END ...............C=32.90344562312671;, score=0.704 total time=   0.0s\n",
      "[CV 2/5] END ...............C=32.90344562312671;, score=0.697 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ...............C=32.90344562312671;, score=0.710 total time=   0.0s\n",
      "[CV 4/5] END ...............C=32.90344562312671;, score=0.698 total time=   0.0s\n",
      "[CV 5/5] END ...............C=32.90344562312671;, score=0.694 total time=   0.0s\n",
      "[CV 1/5] END ...............C=62.10169418915616;, score=0.704 total time=   0.0s\n",
      "[CV 2/5] END ...............C=62.10169418915616;, score=0.697 total time=   0.0s\n",
      "[CV 3/5] END ...............C=62.10169418915616;, score=0.710 total time=   0.0s\n",
      "[CV 4/5] END ...............C=62.10169418915616;, score=0.698 total time=   0.0s\n",
      "[CV 5/5] END ...............C=62.10169418915616;, score=0.694 total time=   0.0s\n",
      "[CV 1/5] END ..............C=117.21022975334793;, score=0.704 total time=   0.0s\n",
      "[CV 2/5] END ..............C=117.21022975334793;, score=0.697 total time=   0.0s\n",
      "[CV 3/5] END ..............C=117.21022975334793;, score=0.710 total time=   0.0s\n",
      "[CV 4/5] END ..............C=117.21022975334793;, score=0.698 total time=   0.0s\n",
      "[CV 5/5] END ..............C=117.21022975334793;, score=0.694 total time=   0.0s\n",
      "[CV 1/5] END ..............C=221.22162910704503;, score=0.704 total time=   0.0s\n",
      "[CV 2/5] END ..............C=221.22162910704503;, score=0.697 total time=   0.0s\n",
      "[CV 3/5] END ..............C=221.22162910704503;, score=0.710 total time=   0.0s\n",
      "[CV 4/5] END ..............C=221.22162910704503;, score=0.698 total time=   0.0s\n",
      "[CV 5/5] END ..............C=221.22162910704503;, score=0.694 total time=   0.0s\n",
      "[CV 1/5] END ..............C=417.53189365604004;, score=0.704 total time=   0.0s\n",
      "[CV 2/5] END ..............C=417.53189365604004;, score=0.697 total time=   0.0s\n",
      "[CV 3/5] END ..............C=417.53189365604004;, score=0.710 total time=   0.0s\n",
      "[CV 4/5] END ..............C=417.53189365604004;, score=0.698 total time=   0.0s\n",
      "[CV 5/5] END ..............C=417.53189365604004;, score=0.694 total time=   0.0s\n",
      "[CV 1/5] END ...............C=788.0462815669904;, score=0.704 total time=   0.0s\n",
      "[CV 2/5] END ...............C=788.0462815669904;, score=0.697 total time=   0.0s\n",
      "[CV 3/5] END ...............C=788.0462815669904;, score=0.710 total time=   0.0s\n",
      "[CV 4/5] END ...............C=788.0462815669904;, score=0.698 total time=   0.0s\n",
      "[CV 5/5] END ...............C=788.0462815669904;, score=0.694 total time=   0.0s\n",
      "[CV 1/5] END ..............C=1487.3521072935118;, score=0.704 total time=   0.0s\n",
      "[CV 2/5] END ..............C=1487.3521072935118;, score=0.697 total time=   0.0s\n",
      "[CV 3/5] END ..............C=1487.3521072935118;, score=0.710 total time=   0.0s\n",
      "[CV 4/5] END ..............C=1487.3521072935118;, score=0.698 total time=   0.0s\n",
      "[CV 5/5] END ..............C=1487.3521072935118;, score=0.694 total time=   0.0s\n",
      "[CV 1/5] END ..............C=2807.2162039411755;, score=0.704 total time=   0.0s\n",
      "[CV 2/5] END ..............C=2807.2162039411755;, score=0.697 total time=   0.0s\n",
      "[CV 3/5] END ..............C=2807.2162039411755;, score=0.710 total time=   0.0s\n",
      "[CV 4/5] END ..............C=2807.2162039411755;, score=0.698 total time=   0.0s\n",
      "[CV 5/5] END ..............C=2807.2162039411755;, score=0.694 total time=   0.0s\n",
      "[CV 1/5] END ...............C=5298.316906283702;, score=0.704 total time=   0.0s\n",
      "[CV 2/5] END ...............C=5298.316906283702;, score=0.697 total time=   0.0s\n",
      "[CV 3/5] END ...............C=5298.316906283702;, score=0.710 total time=   0.0s\n",
      "[CV 4/5] END ...............C=5298.316906283702;, score=0.698 total time=   0.0s\n",
      "[CV 5/5] END ...............C=5298.316906283702;, score=0.694 total time=   0.0s\n",
      "[CV 1/5] END .........................C=10000.0;, score=0.704 total time=   0.0s\n",
      "[CV 2/5] END .........................C=10000.0;, score=0.697 total time=   0.0s\n",
      "[CV 3/5] END .........................C=10000.0;, score=0.710 total time=   0.0s\n",
      "[CV 4/5] END .........................C=10000.0;, score=0.698 total time=   0.0s\n",
      "[CV 5/5] END .........................C=10000.0;, score=0.694 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=10000),\n",
       "             param_grid=[{'C': array([1.00000000e-04, 1.88739182e-04, 3.56224789e-04, 6.72335754e-04,\n",
       "       1.26896100e-03, 2.39502662e-03, 4.52035366e-03, 8.53167852e-03,\n",
       "       1.61026203e-02, 3.03919538e-02, 5.73615251e-02, 1.08263673e-01,\n",
       "       2.04335972e-01, 3.85662042e-01, 7.27895384e-01, 1.37382380e+00,\n",
       "       2.59294380e+00, 4.89390092e+00, 9.23670857e+00, 1.74332882e+01,\n",
       "       3.29034456e+01, 6.21016942e+01, 1.17210230e+02, 2.21221629e+02,\n",
       "       4.17531894e+02, 7.88046282e+02, 1.48735211e+03, 2.80721620e+03,\n",
       "       5.29831691e+03, 1.00000000e+04])}],\n",
       "             scoring='f1', verbose=3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Valeurs à tester de l'hyperparamètre\n",
    "reg_coef =  np.logspace(-4, 4, 30)\n",
    "\n",
    "# Régularisation Ridge (Yeo-Johnson)\n",
    "log_reg = LogisticRegression(penalty='l2', max_iter=10000)\n",
    "tuned_parameters = [{'C': reg_coef}]\n",
    "nb_folds = 5\n",
    "grid = GridSearchCV(log_reg, tuned_parameters, cv=nb_folds, refit=True, verbose=3, scoring='f1')\n",
    "grid.fit(X_train_preprocessed, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1211c7e8-986d-4e46-918e-f09f7215c924",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Question 13.b\n",
    "Quel est le F-score, sur le jeu de test, d'une régression logistique avec régularisation ridge et ce coefficient de régularisation optimal, entraînée sur le jeu d'entraînement ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "52428c16-db07-4202-bf97-8ada338b01b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7014538409120783\n",
      "{'C': 0.20433597178569418}\n",
      "0.7079934747145188\n"
     ]
    }
   ],
   "source": [
    "# Régularisation Ridge (Yeo-Johnson)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "y_pred = grid.best_estimator_.predict(X_test_preprocessed)\n",
    "print(f1_score(y_test, y_pred, average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "815c4065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV 1/5] END ..........................C=0.0001;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END ..........................C=0.0001;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END ..........................C=0.0001;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END ..........................C=0.0001;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END ..........................C=0.0001;, score=0.667 total time=   0.0s\n",
      "[CV 1/5] END ..........C=0.00018873918221350977;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END ..........C=0.00018873918221350977;, score=0.667 total time=   0.0s\n",
      "[CV 3/5] END ..........C=0.00018873918221350977;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END ..........C=0.00018873918221350977;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END ..........C=0.00018873918221350977;, score=0.667 total time=   0.0s\n",
      "[CV 1/5] END ...........C=0.0003562247890262444;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END ...........C=0.0003562247890262444;, score=0.667 total time=   0.0s\n",
      "[CV 3/5] END ...........C=0.0003562247890262444;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END ...........C=0.0003562247890262444;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END ...........C=0.0003562247890262444;, score=0.667 total time=   0.0s\n",
      "[CV 1/5] END ...........C=0.0006723357536499335;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END ...........C=0.0006723357536499335;, score=0.667 total time=   0.0s\n",
      "[CV 3/5] END ...........C=0.0006723357536499335;, score=0.667 total time=   0.0s\n",
      "[CV 4/5] END ...........C=0.0006723357536499335;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END ...........C=0.0006723357536499335;, score=0.667 total time=   0.0s\n",
      "[CV 1/5] END ...........C=0.0012689610031679222;, score=0.667 total time=   0.0s\n",
      "[CV 2/5] END ...........C=0.0012689610031679222;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END ...........C=0.0012689610031679222;, score=0.667 total time=   0.0s\n",
      "[CV 4/5] END ...........C=0.0012689610031679222;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END ...........C=0.0012689610031679222;, score=0.667 total time=   0.0s\n",
      "[CV 1/5] END ............C=0.002395026619987486;, score=0.647 total time=   0.0s\n",
      "[CV 2/5] END ............C=0.002395026619987486;, score=0.661 total time=   0.0s\n",
      "[CV 3/5] END ............C=0.002395026619987486;, score=0.661 total time=   0.0s\n",
      "[CV 4/5] END ............C=0.002395026619987486;, score=0.644 total time=   0.0s\n",
      "[CV 5/5] END ............C=0.002395026619987486;, score=0.626 total time=   0.0s\n",
      "[CV 1/5] END ............C=0.004520353656360241;, score=0.686 total time=   0.0s\n",
      "[CV 2/5] END ............C=0.004520353656360241;, score=0.693 total time=   0.0s\n",
      "[CV 3/5] END ............C=0.004520353656360241;, score=0.704 total time=   0.0s\n",
      "[CV 4/5] END ............C=0.004520353656360241;, score=0.670 total time=   0.0s\n",
      "[CV 5/5] END ............C=0.004520353656360241;, score=0.667 total time=   0.0s\n",
      "[CV 1/5] END ............C=0.008531678524172805;, score=0.693 total time=   0.0s\n",
      "[CV 2/5] END ............C=0.008531678524172805;, score=0.684 total time=   0.0s\n",
      "[CV 3/5] END ............C=0.008531678524172805;, score=0.699 total time=   0.0s\n",
      "[CV 4/5] END ............C=0.008531678524172805;, score=0.671 total time=   0.0s\n",
      "[CV 5/5] END ............C=0.008531678524172805;, score=0.669 total time=   0.0s\n",
      "[CV 1/5] END .............C=0.01610262027560939;, score=0.700 total time=   0.0s\n",
      "[CV 2/5] END .............C=0.01610262027560939;, score=0.690 total time=   0.0s\n",
      "[CV 3/5] END .............C=0.01610262027560939;, score=0.701 total time=   0.0s\n",
      "[CV 4/5] END .............C=0.01610262027560939;, score=0.685 total time=   0.0s\n",
      "[CV 5/5] END .............C=0.01610262027560939;, score=0.679 total time=   0.0s\n",
      "[CV 1/5] END .............C=0.03039195382313198;, score=0.692 total time=   0.0s\n",
      "[CV 2/5] END .............C=0.03039195382313198;, score=0.695 total time=   0.0s\n",
      "[CV 3/5] END .............C=0.03039195382313198;, score=0.712 total time=   0.0s\n",
      "[CV 4/5] END .............C=0.03039195382313198;, score=0.694 total time=   0.0s\n",
      "[CV 5/5] END .............C=0.03039195382313198;, score=0.690 total time=   0.0s\n",
      "[CV 1/5] END .............C=0.05736152510448681;, score=0.692 total time=   0.0s\n",
      "[CV 2/5] END .............C=0.05736152510448681;, score=0.700 total time=   0.0s\n",
      "[CV 3/5] END .............C=0.05736152510448681;, score=0.712 total time=   0.0s\n",
      "[CV 4/5] END .............C=0.05736152510448681;, score=0.698 total time=   0.0s\n",
      "[CV 5/5] END .............C=0.05736152510448681;, score=0.695 total time=   0.0s\n",
      "[CV 1/5] END ..............C=0.1082636733874054;, score=0.695 total time=   0.0s\n",
      "[CV 2/5] END ..............C=0.1082636733874054;, score=0.699 total time=   0.0s\n",
      "[CV 3/5] END ..............C=0.1082636733874054;, score=0.712 total time=   0.0s\n",
      "[CV 4/5] END ..............C=0.1082636733874054;, score=0.699 total time=   0.0s\n",
      "[CV 5/5] END ..............C=0.1082636733874054;, score=0.693 total time=   0.0s\n",
      "[CV 1/5] END .............C=0.20433597178569418;, score=0.702 total time=   0.0s\n",
      "[CV 2/5] END .............C=0.20433597178569418;, score=0.697 total time=   0.0s\n",
      "[CV 3/5] END .............C=0.20433597178569418;, score=0.710 total time=   0.0s\n",
      "[CV 4/5] END .............C=0.20433597178569418;, score=0.698 total time=   0.0s\n",
      "[CV 5/5] END .............C=0.20433597178569418;, score=0.694 total time=   0.0s\n",
      "[CV 1/5] END .............C=0.38566204211634725;, score=0.702 total time=   0.0s\n",
      "[CV 2/5] END .............C=0.38566204211634725;, score=0.695 total time=   0.0s\n",
      "[CV 3/5] END .............C=0.38566204211634725;, score=0.712 total time=   0.0s\n",
      "[CV 4/5] END .............C=0.38566204211634725;, score=0.700 total time=   0.0s\n",
      "[CV 5/5] END .............C=0.38566204211634725;, score=0.694 total time=   0.0s\n",
      "[CV 1/5] END ..............C=0.7278953843983146;, score=0.706 total time=   0.0s\n",
      "[CV 2/5] END ..............C=0.7278953843983146;, score=0.695 total time=   0.0s\n",
      "[CV 3/5] END ..............C=0.7278953843983146;, score=0.711 total time=   0.0s\n",
      "[CV 4/5] END ..............C=0.7278953843983146;, score=0.700 total time=   0.0s\n",
      "[CV 5/5] END ..............C=0.7278953843983146;, score=0.694 total time=   0.0s\n",
      "[CV 1/5] END ..............C=1.3738237958832638;, score=0.706 total time=   0.0s\n",
      "[CV 2/5] END ..............C=1.3738237958832638;, score=0.697 total time=   0.0s\n",
      "[CV 3/5] END ..............C=1.3738237958832638;, score=0.711 total time=   0.0s\n",
      "[CV 4/5] END ..............C=1.3738237958832638;, score=0.701 total time=   0.0s\n",
      "[CV 5/5] END ..............C=1.3738237958832638;, score=0.695 total time=   0.0s\n",
      "[CV 1/5] END ...............C=2.592943797404667;, score=0.704 total time=   0.0s\n",
      "[CV 2/5] END ...............C=2.592943797404667;, score=0.697 total time=   0.0s\n",
      "[CV 3/5] END ...............C=2.592943797404667;, score=0.710 total time=   0.0s\n",
      "[CV 4/5] END ...............C=2.592943797404667;, score=0.700 total time=   0.0s\n",
      "[CV 5/5] END ...............C=2.592943797404667;, score=0.694 total time=   0.0s\n",
      "[CV 1/5] END ...............C=4.893900918477489;, score=0.704 total time=   0.0s\n",
      "[CV 2/5] END ...............C=4.893900918477489;, score=0.697 total time=   0.0s\n",
      "[CV 3/5] END ...............C=4.893900918477489;, score=0.710 total time=   0.0s\n",
      "[CV 4/5] END ...............C=4.893900918477489;, score=0.700 total time=   0.0s\n",
      "[CV 5/5] END ...............C=4.893900918477489;, score=0.694 total time=   0.0s\n",
      "[CV 1/5] END ...............C=9.236708571873866;, score=0.704 total time=   0.0s\n",
      "[CV 2/5] END ...............C=9.236708571873866;, score=0.697 total time=   0.0s\n",
      "[CV 3/5] END ...............C=9.236708571873866;, score=0.710 total time=   0.0s\n",
      "[CV 4/5] END ...............C=9.236708571873866;, score=0.698 total time=   0.0s\n",
      "[CV 5/5] END ...............C=9.236708571873866;, score=0.694 total time=   0.0s\n",
      "[CV 1/5] END ..............C=17.433288221999874;, score=0.704 total time=   0.0s\n",
      "[CV 2/5] END ..............C=17.433288221999874;, score=0.697 total time=   0.0s\n",
      "[CV 3/5] END ..............C=17.433288221999874;, score=0.710 total time=   0.0s\n",
      "[CV 4/5] END ..............C=17.433288221999874;, score=0.698 total time=   0.0s\n",
      "[CV 5/5] END ..............C=17.433288221999874;, score=0.694 total time=   0.0s\n",
      "[CV 1/5] END ...............C=32.90344562312671;, score=0.704 total time=   0.0s\n",
      "[CV 2/5] END ...............C=32.90344562312671;, score=0.697 total time=   0.0s\n",
      "[CV 3/5] END ...............C=32.90344562312671;, score=0.710 total time=   0.0s\n",
      "[CV 4/5] END ...............C=32.90344562312671;, score=0.698 total time=   0.0s\n",
      "[CV 5/5] END ...............C=32.90344562312671;, score=0.694 total time=   0.0s\n",
      "[CV 1/5] END ...............C=62.10169418915616;, score=0.704 total time=   0.0s\n",
      "[CV 2/5] END ...............C=62.10169418915616;, score=0.697 total time=   0.0s\n",
      "[CV 3/5] END ...............C=62.10169418915616;, score=0.710 total time=   0.0s\n",
      "[CV 4/5] END ...............C=62.10169418915616;, score=0.698 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ...............C=62.10169418915616;, score=0.694 total time=   0.0s\n",
      "[CV 1/5] END ..............C=117.21022975334793;, score=0.704 total time=   0.0s\n",
      "[CV 2/5] END ..............C=117.21022975334793;, score=0.697 total time=   0.0s\n",
      "[CV 3/5] END ..............C=117.21022975334793;, score=0.710 total time=   0.0s\n",
      "[CV 4/5] END ..............C=117.21022975334793;, score=0.698 total time=   0.0s\n",
      "[CV 5/5] END ..............C=117.21022975334793;, score=0.694 total time=   0.0s\n",
      "[CV 1/5] END ..............C=221.22162910704503;, score=0.704 total time=   0.0s\n",
      "[CV 2/5] END ..............C=221.22162910704503;, score=0.697 total time=   0.0s\n",
      "[CV 3/5] END ..............C=221.22162910704503;, score=0.710 total time=   0.0s\n",
      "[CV 4/5] END ..............C=221.22162910704503;, score=0.698 total time=   0.0s\n",
      "[CV 5/5] END ..............C=221.22162910704503;, score=0.694 total time=   0.0s\n",
      "[CV 1/5] END ..............C=417.53189365604004;, score=0.704 total time=   0.0s\n",
      "[CV 2/5] END ..............C=417.53189365604004;, score=0.697 total time=   0.0s\n",
      "[CV 3/5] END ..............C=417.53189365604004;, score=0.710 total time=   0.0s\n",
      "[CV 4/5] END ..............C=417.53189365604004;, score=0.698 total time=   0.0s\n",
      "[CV 5/5] END ..............C=417.53189365604004;, score=0.694 total time=   0.0s\n",
      "[CV 1/5] END ...............C=788.0462815669904;, score=0.704 total time=   0.0s\n",
      "[CV 2/5] END ...............C=788.0462815669904;, score=0.697 total time=   0.0s\n",
      "[CV 3/5] END ...............C=788.0462815669904;, score=0.710 total time=   0.0s\n",
      "[CV 4/5] END ...............C=788.0462815669904;, score=0.698 total time=   0.0s\n",
      "[CV 5/5] END ...............C=788.0462815669904;, score=0.694 total time=   0.0s\n",
      "[CV 1/5] END ..............C=1487.3521072935118;, score=0.704 total time=   0.0s\n",
      "[CV 2/5] END ..............C=1487.3521072935118;, score=0.697 total time=   0.0s\n",
      "[CV 3/5] END ..............C=1487.3521072935118;, score=0.710 total time=   0.0s\n",
      "[CV 4/5] END ..............C=1487.3521072935118;, score=0.698 total time=   0.0s\n",
      "[CV 5/5] END ..............C=1487.3521072935118;, score=0.694 total time=   0.0s\n",
      "[CV 1/5] END ..............C=2807.2162039411755;, score=0.704 total time=   0.0s\n",
      "[CV 2/5] END ..............C=2807.2162039411755;, score=0.697 total time=   0.0s\n",
      "[CV 3/5] END ..............C=2807.2162039411755;, score=0.710 total time=   0.0s\n",
      "[CV 4/5] END ..............C=2807.2162039411755;, score=0.698 total time=   0.0s\n",
      "[CV 5/5] END ..............C=2807.2162039411755;, score=0.694 total time=   0.0s\n",
      "[CV 1/5] END ...............C=5298.316906283702;, score=0.704 total time=   0.0s\n",
      "[CV 2/5] END ...............C=5298.316906283702;, score=0.697 total time=   0.0s\n",
      "[CV 3/5] END ...............C=5298.316906283702;, score=0.710 total time=   0.0s\n",
      "[CV 4/5] END ...............C=5298.316906283702;, score=0.698 total time=   0.0s\n",
      "[CV 5/5] END ...............C=5298.316906283702;, score=0.694 total time=   0.0s\n",
      "[CV 1/5] END .........................C=10000.0;, score=0.704 total time=   0.0s\n",
      "[CV 2/5] END .........................C=10000.0;, score=0.697 total time=   0.0s\n",
      "[CV 3/5] END .........................C=10000.0;, score=0.710 total time=   0.0s\n",
      "[CV 4/5] END .........................C=10000.0;, score=0.698 total time=   0.0s\n",
      "[CV 5/5] END .........................C=10000.0;, score=0.694 total time=   0.0s\n",
      "0.7016959487779911\n",
      "{'C': 1.3738237958832638}\n",
      "0.7079934747145188\n"
     ]
    }
   ],
   "source": [
    "# Régularisation Lasso (Yeo-Johnson)\n",
    "\n",
    "log_reg = LogisticRegression(penalty='l1', max_iter=10000, solver='saga')\n",
    "tuned_parameters = [{'C': reg_coef}]\n",
    "nb_folds = 5\n",
    "grid = GridSearchCV(log_reg, tuned_parameters, cv=nb_folds, refit=True, verbose=3, scoring='f1')\n",
    "grid.fit(X_train_preprocessed, y_train)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "y_pred = grid.best_estimator_.predict(X_test_preprocessed)\n",
    "print(f1_score(y_test, y_pred, average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b9ba0f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV 1/5] END ..........................C=0.0001;, score=0.667 total time=   0.0s\n",
      "[CV 2/5] END ..........................C=0.0001;, score=0.667 total time=   0.0s\n",
      "[CV 3/5] END ..........................C=0.0001;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END ..........................C=0.0001;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END ..........................C=0.0001;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END ..........C=0.00018873918221350977;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END ..........C=0.00018873918221350977;, score=0.667 total time=   0.0s\n",
      "[CV 3/5] END ..........C=0.00018873918221350977;, score=0.667 total time=   0.0s\n",
      "[CV 4/5] END ..........C=0.00018873918221350977;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END ..........C=0.00018873918221350977;, score=0.667 total time=   0.0s\n",
      "[CV 1/5] END ...........C=0.0003562247890262444;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END ...........C=0.0003562247890262444;, score=0.667 total time=   0.0s\n",
      "[CV 3/5] END ...........C=0.0003562247890262444;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END ...........C=0.0003562247890262444;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END ...........C=0.0003562247890262444;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END ...........C=0.0006723357536499335;, score=0.667 total time=   0.0s\n",
      "[CV 2/5] END ...........C=0.0006723357536499335;, score=0.000 total time=   0.0s\n",
      "[CV 3/5] END ...........C=0.0006723357536499335;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END ...........C=0.0006723357536499335;, score=0.000 total time=   0.0s\n",
      "[CV 5/5] END ...........C=0.0006723357536499335;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END ...........C=0.0012689610031679222;, score=0.000 total time=   0.0s\n",
      "[CV 2/5] END ...........C=0.0012689610031679222;, score=0.667 total time=   0.0s\n",
      "[CV 3/5] END ...........C=0.0012689610031679222;, score=0.000 total time=   0.0s\n",
      "[CV 4/5] END ...........C=0.0012689610031679222;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END ...........C=0.0012689610031679222;, score=0.000 total time=   0.0s\n",
      "[CV 1/5] END ............C=0.002395026619987486;, score=0.779 total time=   0.0s\n",
      "[CV 2/5] END ............C=0.002395026619987486;, score=0.782 total time=   0.0s\n",
      "[CV 3/5] END ............C=0.002395026619987486;, score=0.787 total time=   0.0s\n",
      "[CV 4/5] END ............C=0.002395026619987486;, score=0.767 total time=   0.0s\n",
      "[CV 5/5] END ............C=0.002395026619987486;, score=0.773 total time=   0.0s\n",
      "[CV 1/5] END ............C=0.004520353656360241;, score=0.801 total time=   0.0s\n",
      "[CV 2/5] END ............C=0.004520353656360241;, score=0.765 total time=   0.0s\n",
      "[CV 3/5] END ............C=0.004520353656360241;, score=0.793 total time=   0.0s\n",
      "[CV 4/5] END ............C=0.004520353656360241;, score=0.779 total time=   0.0s\n",
      "[CV 5/5] END ............C=0.004520353656360241;, score=0.785 total time=   0.0s\n",
      "[CV 1/5] END ............C=0.008531678524172805;, score=0.796 total time=   0.0s\n",
      "[CV 2/5] END ............C=0.008531678524172805;, score=0.761 total time=   0.0s\n",
      "[CV 3/5] END ............C=0.008531678524172805;, score=0.790 total time=   0.0s\n",
      "[CV 4/5] END ............C=0.008531678524172805;, score=0.770 total time=   0.0s\n",
      "[CV 5/5] END ............C=0.008531678524172805;, score=0.776 total time=   0.0s\n",
      "[CV 1/5] END .............C=0.01610262027560939;, score=0.791 total time=   0.0s\n",
      "[CV 2/5] END .............C=0.01610262027560939;, score=0.763 total time=   0.0s\n",
      "[CV 3/5] END .............C=0.01610262027560939;, score=0.793 total time=   0.0s\n",
      "[CV 4/5] END .............C=0.01610262027560939;, score=0.770 total time=   0.0s\n",
      "[CV 5/5] END .............C=0.01610262027560939;, score=0.780 total time=   0.0s\n",
      "[CV 1/5] END .............C=0.03039195382313198;, score=0.779 total time=   0.0s\n",
      "[CV 2/5] END .............C=0.03039195382313198;, score=0.769 total time=   0.0s\n",
      "[CV 3/5] END .............C=0.03039195382313198;, score=0.781 total time=   0.0s\n",
      "[CV 4/5] END .............C=0.03039195382313198;, score=0.772 total time=   0.0s\n",
      "[CV 5/5] END .............C=0.03039195382313198;, score=0.782 total time=   0.0s\n",
      "[CV 1/5] END .............C=0.05736152510448681;, score=0.777 total time=   0.0s\n",
      "[CV 2/5] END .............C=0.05736152510448681;, score=0.772 total time=   0.0s\n",
      "[CV 3/5] END .............C=0.05736152510448681;, score=0.782 total time=   0.0s\n",
      "[CV 4/5] END .............C=0.05736152510448681;, score=0.772 total time=   0.0s\n",
      "[CV 5/5] END .............C=0.05736152510448681;, score=0.781 total time=   0.0s\n",
      "[CV 1/5] END ..............C=0.1082636733874054;, score=0.774 total time=   0.0s\n",
      "[CV 2/5] END ..............C=0.1082636733874054;, score=0.770 total time=   0.0s\n",
      "[CV 3/5] END ..............C=0.1082636733874054;, score=0.779 total time=   0.0s\n",
      "[CV 4/5] END ..............C=0.1082636733874054;, score=0.765 total time=   0.0s\n",
      "[CV 5/5] END ..............C=0.1082636733874054;, score=0.778 total time=   0.0s\n",
      "[CV 1/5] END .............C=0.20433597178569418;, score=0.773 total time=   0.0s\n",
      "[CV 2/5] END .............C=0.20433597178569418;, score=0.773 total time=   0.2s\n",
      "[CV 3/5] END .............C=0.20433597178569418;, score=0.779 total time=   0.0s\n",
      "[CV 4/5] END .............C=0.20433597178569418;, score=0.764 total time=   0.0s\n",
      "[CV 5/5] END .............C=0.20433597178569418;, score=0.773 total time=   0.0s\n",
      "[CV 1/5] END .............C=0.38566204211634725;, score=0.772 total time=   0.0s\n",
      "[CV 2/5] END .............C=0.38566204211634725;, score=0.772 total time=   0.0s\n",
      "[CV 3/5] END .............C=0.38566204211634725;, score=0.775 total time=   0.3s\n",
      "[CV 4/5] END .............C=0.38566204211634725;, score=0.761 total time=   0.2s\n",
      "[CV 5/5] END .............C=0.38566204211634725;, score=0.775 total time=   0.1s\n",
      "[CV 1/5] END ..............C=0.7278953843983146;, score=0.771 total time=   0.2s\n",
      "[CV 2/5] END ..............C=0.7278953843983146;, score=0.775 total time=   0.4s\n",
      "[CV 3/5] END ..............C=0.7278953843983146;, score=0.776 total time=   0.0s\n",
      "[CV 4/5] END ..............C=0.7278953843983146;, score=0.760 total time=   0.1s\n",
      "[CV 5/5] END ..............C=0.7278953843983146;, score=0.777 total time=   0.2s\n",
      "[CV 1/5] END ..............C=1.3738237958832638;, score=0.774 total time=   0.3s\n",
      "[CV 2/5] END ..............C=1.3738237958832638;, score=0.775 total time=   0.0s\n",
      "[CV 3/5] END ..............C=1.3738237958832638;, score=0.774 total time=   0.0s\n",
      "[CV 4/5] END ..............C=1.3738237958832638;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END ..............C=1.3738237958832638;, score=0.777 total time=   0.0s\n",
      "[CV 1/5] END ...............C=2.592943797404667;, score=0.774 total time=   0.1s\n",
      "[CV 2/5] END ...............C=2.592943797404667;, score=0.771 total time=   0.5s\n",
      "[CV 3/5] END ...............C=2.592943797404667;, score=0.774 total time=   0.4s\n",
      "[CV 4/5] END ...............C=2.592943797404667;, score=0.761 total time=   0.4s\n",
      "[CV 5/5] END ...............C=2.592943797404667;, score=0.777 total time=   0.2s\n",
      "[CV 1/5] END ...............C=4.893900918477489;, score=0.774 total time=   0.2s\n",
      "[CV 2/5] END ...............C=4.893900918477489;, score=0.770 total time=   0.5s\n",
      "[CV 3/5] END ...............C=4.893900918477489;, score=0.777 total time=   0.4s\n",
      "[CV 4/5] END ...............C=4.893900918477489;, score=0.761 total time=   0.4s\n",
      "[CV 5/5] END ...............C=4.893900918477489;, score=0.779 total time=   0.3s\n",
      "[CV 1/5] END ...............C=9.236708571873866;, score=0.774 total time=   0.3s\n",
      "[CV 2/5] END ...............C=9.236708571873866;, score=0.771 total time=   0.4s\n",
      "[CV 3/5] END ...............C=9.236708571873866;, score=0.775 total time=   0.5s\n",
      "[CV 4/5] END ...............C=9.236708571873866;, score=0.761 total time=   0.4s\n",
      "[CV 5/5] END ...............C=9.236708571873866;, score=0.777 total time=   0.3s\n",
      "[CV 1/5] END ..............C=17.433288221999874;, score=0.774 total time=   0.3s\n",
      "[CV 2/5] END ..............C=17.433288221999874;, score=0.772 total time=   0.4s\n",
      "[CV 3/5] END ..............C=17.433288221999874;, score=0.775 total time=   0.4s\n",
      "[CV 4/5] END ..............C=17.433288221999874;, score=0.761 total time=   0.4s\n",
      "[CV 5/5] END ..............C=17.433288221999874;, score=0.776 total time=   0.4s\n",
      "[CV 1/5] END ...............C=32.90344562312671;, score=0.772 total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ...............C=32.90344562312671;, score=0.772 total time=   0.6s\n",
      "[CV 3/5] END ...............C=32.90344562312671;, score=0.775 total time=   0.5s\n",
      "[CV 4/5] END ...............C=32.90344562312671;, score=0.761 total time=   0.5s\n",
      "[CV 5/5] END ...............C=32.90344562312671;, score=0.776 total time=   0.5s\n",
      "[CV 1/5] END ...............C=62.10169418915616;, score=0.772 total time=   0.4s\n",
      "[CV 2/5] END ...............C=62.10169418915616;, score=0.772 total time=   0.4s\n",
      "[CV 3/5] END ...............C=62.10169418915616;, score=0.775 total time=   0.4s\n",
      "[CV 4/5] END ...............C=62.10169418915616;, score=0.761 total time=   0.4s\n",
      "[CV 5/5] END ...............C=62.10169418915616;, score=0.776 total time=   0.4s\n",
      "[CV 1/5] END ..............C=117.21022975334793;, score=0.772 total time=   0.3s\n",
      "[CV 2/5] END ..............C=117.21022975334793;, score=0.772 total time=   0.4s\n",
      "[CV 3/5] END ..............C=117.21022975334793;, score=0.775 total time=   0.5s\n",
      "[CV 4/5] END ..............C=117.21022975334793;, score=0.761 total time=   0.4s\n",
      "[CV 5/5] END ..............C=117.21022975334793;, score=0.777 total time=   0.4s\n",
      "[CV 1/5] END ..............C=221.22162910704503;, score=0.772 total time=   0.3s\n",
      "[CV 2/5] END ..............C=221.22162910704503;, score=0.772 total time=   0.4s\n",
      "[CV 3/5] END ..............C=221.22162910704503;, score=0.775 total time=   0.4s\n",
      "[CV 4/5] END ..............C=221.22162910704503;, score=0.761 total time=   0.4s\n",
      "[CV 5/5] END ..............C=221.22162910704503;, score=0.777 total time=   0.4s\n",
      "[CV 1/5] END ..............C=417.53189365604004;, score=0.772 total time=   0.3s\n",
      "[CV 2/5] END ..............C=417.53189365604004;, score=0.772 total time=   0.5s\n",
      "[CV 3/5] END ..............C=417.53189365604004;, score=0.775 total time=   0.4s\n",
      "[CV 4/5] END ..............C=417.53189365604004;, score=0.761 total time=   0.5s\n",
      "[CV 5/5] END ..............C=417.53189365604004;, score=0.777 total time=   0.4s\n",
      "[CV 1/5] END ...............C=788.0462815669904;, score=0.772 total time=   0.4s\n",
      "[CV 2/5] END ...............C=788.0462815669904;, score=0.772 total time=   0.4s\n",
      "[CV 3/5] END ...............C=788.0462815669904;, score=0.775 total time=   0.4s\n",
      "[CV 4/5] END ...............C=788.0462815669904;, score=0.761 total time=   0.4s\n",
      "[CV 5/5] END ...............C=788.0462815669904;, score=0.777 total time=   0.4s\n",
      "[CV 1/5] END ..............C=1487.3521072935118;, score=0.772 total time=   0.4s\n",
      "[CV 2/5] END ..............C=1487.3521072935118;, score=0.772 total time=   0.4s\n",
      "[CV 3/5] END ..............C=1487.3521072935118;, score=0.775 total time=   0.4s\n",
      "[CV 4/5] END ..............C=1487.3521072935118;, score=0.761 total time=   0.5s\n",
      "[CV 5/5] END ..............C=1487.3521072935118;, score=0.777 total time=   0.3s\n",
      "[CV 1/5] END ..............C=2807.2162039411755;, score=0.772 total time=   0.4s\n",
      "[CV 2/5] END ..............C=2807.2162039411755;, score=0.772 total time=   0.5s\n",
      "[CV 3/5] END ..............C=2807.2162039411755;, score=0.775 total time=   0.4s\n",
      "[CV 4/5] END ..............C=2807.2162039411755;, score=0.761 total time=   0.4s\n",
      "[CV 5/5] END ..............C=2807.2162039411755;, score=0.777 total time=   0.4s\n",
      "[CV 1/5] END ...............C=5298.316906283702;, score=0.772 total time=   0.4s\n",
      "[CV 2/5] END ...............C=5298.316906283702;, score=0.772 total time=   0.5s\n",
      "[CV 3/5] END ...............C=5298.316906283702;, score=0.775 total time=   0.4s\n",
      "[CV 4/5] END ...............C=5298.316906283702;, score=0.761 total time=   0.4s\n",
      "[CV 5/5] END ...............C=5298.316906283702;, score=0.777 total time=   0.4s\n",
      "[CV 1/5] END .........................C=10000.0;, score=0.772 total time=   0.4s\n",
      "[CV 2/5] END .........................C=10000.0;, score=0.772 total time=   0.4s\n",
      "[CV 3/5] END .........................C=10000.0;, score=0.775 total time=   0.5s\n",
      "[CV 4/5] END .........................C=10000.0;, score=0.761 total time=   0.5s\n",
      "[CV 5/5] END .........................C=10000.0;, score=0.777 total time=   0.4s\n",
      "0.7844294511082107\n",
      "{'C': 0.004520353656360241}\n",
      "0.7768729641693811\n"
     ]
    }
   ],
   "source": [
    "# Régularisation lasso (StandardScaler)\n",
    "\n",
    "log_reg_s = LogisticRegression(penalty='l1', max_iter=10000, solver='saga')\n",
    "reg_coef =  np.logspace(-4, 4, 30)\n",
    "tuned_parameters = [{'C': reg_coef}]\n",
    "nb_folds = 5\n",
    "grid_s = GridSearchCV(log_reg_s, tuned_parameters, cv=nb_folds, refit=True, verbose=3, scoring='f1')\n",
    "grid_s.fit(X_train_preprocessed_s, y_train)\n",
    "print(grid_s.best_score_)\n",
    "print(grid_s.best_params_)\n",
    "y_pred_s = grid_s.best_estimator_.predict(X_test_preprocessed_s)\n",
    "print(f1_score(y_test, y_pred_s, average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "68ce92ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV 1/5] END ..........................C=0.0001;, score=0.731 total time=   0.0s\n",
      "[CV 2/5] END ..........................C=0.0001;, score=0.706 total time=   0.0s\n",
      "[CV 3/5] END ..........................C=0.0001;, score=0.736 total time=   0.0s\n",
      "[CV 4/5] END ..........................C=0.0001;, score=0.718 total time=   0.0s\n",
      "[CV 5/5] END ..........................C=0.0001;, score=0.725 total time=   0.0s\n",
      "[CV 1/5] END ..........C=0.00018873918221350977;, score=0.733 total time=   0.0s\n",
      "[CV 2/5] END ..........C=0.00018873918221350977;, score=0.709 total time=   0.0s\n",
      "[CV 3/5] END ..........C=0.00018873918221350977;, score=0.741 total time=   0.0s\n",
      "[CV 4/5] END ..........C=0.00018873918221350977;, score=0.722 total time=   0.0s\n",
      "[CV 5/5] END ..........C=0.00018873918221350977;, score=0.736 total time=   0.0s\n",
      "[CV 1/5] END ...........C=0.0003562247890262444;, score=0.749 total time=   0.0s\n",
      "[CV 2/5] END ...........C=0.0003562247890262444;, score=0.714 total time=   0.0s\n",
      "[CV 3/5] END ...........C=0.0003562247890262444;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END ...........C=0.0003562247890262444;, score=0.732 total time=   0.0s\n",
      "[CV 5/5] END ...........C=0.0003562247890262444;, score=0.743 total time=   0.0s\n",
      "[CV 1/5] END ...........C=0.0006723357536499335;, score=0.765 total time=   0.0s\n",
      "[CV 2/5] END ...........C=0.0006723357536499335;, score=0.736 total time=   0.0s\n",
      "[CV 3/5] END ...........C=0.0006723357536499335;, score=0.756 total time=   0.0s\n",
      "[CV 4/5] END ...........C=0.0006723357536499335;, score=0.741 total time=   0.0s\n",
      "[CV 5/5] END ...........C=0.0006723357536499335;, score=0.759 total time=   0.0s\n",
      "[CV 1/5] END ...........C=0.0012689610031679222;, score=0.773 total time=   0.0s\n",
      "[CV 2/5] END ...........C=0.0012689610031679222;, score=0.751 total time=   0.0s\n",
      "[CV 3/5] END ...........C=0.0012689610031679222;, score=0.764 total time=   0.0s\n",
      "[CV 4/5] END ...........C=0.0012689610031679222;, score=0.747 total time=   0.0s\n",
      "[CV 5/5] END ...........C=0.0012689610031679222;, score=0.769 total time=   0.0s\n",
      "[CV 1/5] END ............C=0.002395026619987486;, score=0.775 total time=   0.0s\n",
      "[CV 2/5] END ............C=0.002395026619987486;, score=0.757 total time=   0.0s\n",
      "[CV 3/5] END ............C=0.002395026619987486;, score=0.767 total time=   0.0s\n",
      "[CV 4/5] END ............C=0.002395026619987486;, score=0.756 total time=   0.0s\n",
      "[CV 5/5] END ............C=0.002395026619987486;, score=0.776 total time=   0.0s\n",
      "[CV 1/5] END ............C=0.004520353656360241;, score=0.775 total time=   0.0s\n",
      "[CV 2/5] END ............C=0.004520353656360241;, score=0.762 total time=   0.0s\n",
      "[CV 3/5] END ............C=0.004520353656360241;, score=0.763 total time=   0.0s\n",
      "[CV 4/5] END ............C=0.004520353656360241;, score=0.758 total time=   0.0s\n",
      "[CV 5/5] END ............C=0.004520353656360241;, score=0.778 total time=   0.0s\n",
      "[CV 1/5] END ............C=0.008531678524172805;, score=0.772 total time=   0.0s\n",
      "[CV 2/5] END ............C=0.008531678524172805;, score=0.765 total time=   0.0s\n",
      "[CV 3/5] END ............C=0.008531678524172805;, score=0.770 total time=   0.0s\n",
      "[CV 4/5] END ............C=0.008531678524172805;, score=0.758 total time=   0.0s\n",
      "[CV 5/5] END ............C=0.008531678524172805;, score=0.775 total time=   0.0s\n",
      "[CV 1/5] END .............C=0.01610262027560939;, score=0.776 total time=   0.0s\n",
      "[CV 2/5] END .............C=0.01610262027560939;, score=0.778 total time=   0.0s\n",
      "[CV 3/5] END .............C=0.01610262027560939;, score=0.769 total time=   0.0s\n",
      "[CV 4/5] END .............C=0.01610262027560939;, score=0.757 total time=   0.0s\n",
      "[CV 5/5] END .............C=0.01610262027560939;, score=0.777 total time=   0.0s\n",
      "[CV 1/5] END .............C=0.03039195382313198;, score=0.770 total time=   0.0s\n",
      "[CV 2/5] END .............C=0.03039195382313198;, score=0.771 total time=   0.0s\n",
      "[CV 3/5] END .............C=0.03039195382313198;, score=0.772 total time=   0.0s\n",
      "[CV 4/5] END .............C=0.03039195382313198;, score=0.760 total time=   0.0s\n",
      "[CV 5/5] END .............C=0.03039195382313198;, score=0.777 total time=   0.0s\n",
      "[CV 1/5] END .............C=0.05736152510448681;, score=0.768 total time=   0.0s\n",
      "[CV 2/5] END .............C=0.05736152510448681;, score=0.771 total time=   0.0s\n",
      "[CV 3/5] END .............C=0.05736152510448681;, score=0.773 total time=   0.0s\n",
      "[CV 4/5] END .............C=0.05736152510448681;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END .............C=0.05736152510448681;, score=0.776 total time=   0.0s\n",
      "[CV 1/5] END ..............C=0.1082636733874054;, score=0.770 total time=   0.0s\n",
      "[CV 2/5] END ..............C=0.1082636733874054;, score=0.773 total time=   0.0s\n",
      "[CV 3/5] END ..............C=0.1082636733874054;, score=0.775 total time=   0.0s\n",
      "[CV 4/5] END ..............C=0.1082636733874054;, score=0.758 total time=   0.0s\n",
      "[CV 5/5] END ..............C=0.1082636733874054;, score=0.777 total time=   0.0s\n",
      "[CV 1/5] END .............C=0.20433597178569418;, score=0.770 total time=   0.0s\n",
      "[CV 2/5] END .............C=0.20433597178569418;, score=0.774 total time=   0.0s\n",
      "[CV 3/5] END .............C=0.20433597178569418;, score=0.775 total time=   0.0s\n",
      "[CV 4/5] END .............C=0.20433597178569418;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END .............C=0.20433597178569418;, score=0.776 total time=   0.0s\n",
      "[CV 1/5] END .............C=0.38566204211634725;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END .............C=0.38566204211634725;, score=0.775 total time=   0.0s\n",
      "[CV 3/5] END .............C=0.38566204211634725;, score=0.775 total time=   0.0s\n",
      "[CV 4/5] END .............C=0.38566204211634725;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END .............C=0.38566204211634725;, score=0.776 total time=   0.0s\n",
      "[CV 1/5] END ..............C=0.7278953843983146;, score=0.774 total time=   0.0s\n",
      "[CV 2/5] END ..............C=0.7278953843983146;, score=0.774 total time=   0.0s\n",
      "[CV 3/5] END ..............C=0.7278953843983146;, score=0.774 total time=   0.0s\n",
      "[CV 4/5] END ..............C=0.7278953843983146;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END ..............C=0.7278953843983146;, score=0.777 total time=   0.0s\n",
      "[CV 1/5] END ..............C=1.3738237958832638;, score=0.773 total time=   0.0s\n",
      "[CV 2/5] END ..............C=1.3738237958832638;, score=0.771 total time=   0.0s\n",
      "[CV 3/5] END ..............C=1.3738237958832638;, score=0.774 total time=   0.0s\n",
      "[CV 4/5] END ..............C=1.3738237958832638;, score=0.759 total time=   0.0s\n",
      "[CV 5/5] END ..............C=1.3738237958832638;, score=0.777 total time=   0.0s\n",
      "[CV 1/5] END ...............C=2.592943797404667;, score=0.774 total time=   0.0s\n",
      "[CV 2/5] END ...............C=2.592943797404667;, score=0.770 total time=   0.0s\n",
      "[CV 3/5] END ...............C=2.592943797404667;, score=0.774 total time=   0.0s\n",
      "[CV 4/5] END ...............C=2.592943797404667;, score=0.761 total time=   0.0s\n",
      "[CV 5/5] END ...............C=2.592943797404667;, score=0.779 total time=   0.0s\n",
      "[CV 1/5] END ...............C=4.893900918477489;, score=0.774 total time=   0.0s\n",
      "[CV 2/5] END ...............C=4.893900918477489;, score=0.770 total time=   0.0s\n",
      "[CV 3/5] END ...............C=4.893900918477489;, score=0.777 total time=   0.0s\n",
      "[CV 4/5] END ...............C=4.893900918477489;, score=0.761 total time=   0.0s\n",
      "[CV 5/5] END ...............C=4.893900918477489;, score=0.779 total time=   0.0s\n",
      "[CV 1/5] END ...............C=9.236708571873866;, score=0.774 total time=   0.0s\n",
      "[CV 2/5] END ...............C=9.236708571873866;, score=0.772 total time=   0.0s\n",
      "[CV 3/5] END ...............C=9.236708571873866;, score=0.775 total time=   0.0s\n",
      "[CV 4/5] END ...............C=9.236708571873866;, score=0.761 total time=   0.0s\n",
      "[CV 5/5] END ...............C=9.236708571873866;, score=0.776 total time=   0.0s\n",
      "[CV 1/5] END ..............C=17.433288221999874;, score=0.772 total time=   0.0s\n",
      "[CV 2/5] END ..............C=17.433288221999874;, score=0.772 total time=   0.0s\n",
      "[CV 3/5] END ..............C=17.433288221999874;, score=0.775 total time=   0.0s\n",
      "[CV 4/5] END ..............C=17.433288221999874;, score=0.761 total time=   0.0s\n",
      "[CV 5/5] END ..............C=17.433288221999874;, score=0.776 total time=   0.0s\n",
      "[CV 1/5] END ...............C=32.90344562312671;, score=0.772 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ...............C=32.90344562312671;, score=0.772 total time=   0.0s\n",
      "[CV 3/5] END ...............C=32.90344562312671;, score=0.775 total time=   0.0s\n",
      "[CV 4/5] END ...............C=32.90344562312671;, score=0.761 total time=   0.0s\n",
      "[CV 5/5] END ...............C=32.90344562312671;, score=0.776 total time=   0.0s\n",
      "[CV 1/5] END ...............C=62.10169418915616;, score=0.772 total time=   0.0s\n",
      "[CV 2/5] END ...............C=62.10169418915616;, score=0.772 total time=   0.0s\n",
      "[CV 3/5] END ...............C=62.10169418915616;, score=0.775 total time=   0.0s\n",
      "[CV 4/5] END ...............C=62.10169418915616;, score=0.761 total time=   0.0s\n",
      "[CV 5/5] END ...............C=62.10169418915616;, score=0.777 total time=   0.0s\n",
      "[CV 1/5] END ..............C=117.21022975334793;, score=0.772 total time=   0.0s\n",
      "[CV 2/5] END ..............C=117.21022975334793;, score=0.772 total time=   0.0s\n",
      "[CV 3/5] END ..............C=117.21022975334793;, score=0.775 total time=   0.0s\n",
      "[CV 4/5] END ..............C=117.21022975334793;, score=0.761 total time=   0.0s\n",
      "[CV 5/5] END ..............C=117.21022975334793;, score=0.777 total time=   0.0s\n",
      "[CV 1/5] END ..............C=221.22162910704503;, score=0.772 total time=   0.0s\n",
      "[CV 2/5] END ..............C=221.22162910704503;, score=0.772 total time=   0.0s\n",
      "[CV 3/5] END ..............C=221.22162910704503;, score=0.775 total time=   0.0s\n",
      "[CV 4/5] END ..............C=221.22162910704503;, score=0.761 total time=   0.0s\n",
      "[CV 5/5] END ..............C=221.22162910704503;, score=0.777 total time=   0.0s\n",
      "[CV 1/5] END ..............C=417.53189365604004;, score=0.772 total time=   0.0s\n",
      "[CV 2/5] END ..............C=417.53189365604004;, score=0.772 total time=   0.0s\n",
      "[CV 3/5] END ..............C=417.53189365604004;, score=0.775 total time=   0.0s\n",
      "[CV 4/5] END ..............C=417.53189365604004;, score=0.761 total time=   0.0s\n",
      "[CV 5/5] END ..............C=417.53189365604004;, score=0.777 total time=   0.0s\n",
      "[CV 1/5] END ...............C=788.0462815669904;, score=0.772 total time=   0.0s\n",
      "[CV 2/5] END ...............C=788.0462815669904;, score=0.772 total time=   0.0s\n",
      "[CV 3/5] END ...............C=788.0462815669904;, score=0.775 total time=   0.0s\n",
      "[CV 4/5] END ...............C=788.0462815669904;, score=0.761 total time=   0.0s\n",
      "[CV 5/5] END ...............C=788.0462815669904;, score=0.777 total time=   0.0s\n",
      "[CV 1/5] END ..............C=1487.3521072935118;, score=0.772 total time=   0.0s\n",
      "[CV 2/5] END ..............C=1487.3521072935118;, score=0.772 total time=   0.0s\n",
      "[CV 3/5] END ..............C=1487.3521072935118;, score=0.775 total time=   0.0s\n",
      "[CV 4/5] END ..............C=1487.3521072935118;, score=0.761 total time=   0.0s\n",
      "[CV 5/5] END ..............C=1487.3521072935118;, score=0.777 total time=   0.0s\n",
      "[CV 1/5] END ..............C=2807.2162039411755;, score=0.772 total time=   0.0s\n",
      "[CV 2/5] END ..............C=2807.2162039411755;, score=0.772 total time=   0.0s\n",
      "[CV 3/5] END ..............C=2807.2162039411755;, score=0.775 total time=   0.0s\n",
      "[CV 4/5] END ..............C=2807.2162039411755;, score=0.761 total time=   0.0s\n",
      "[CV 5/5] END ..............C=2807.2162039411755;, score=0.777 total time=   0.0s\n",
      "[CV 1/5] END ...............C=5298.316906283702;, score=0.772 total time=   0.0s\n",
      "[CV 2/5] END ...............C=5298.316906283702;, score=0.772 total time=   0.0s\n",
      "[CV 3/5] END ...............C=5298.316906283702;, score=0.775 total time=   0.0s\n",
      "[CV 4/5] END ...............C=5298.316906283702;, score=0.761 total time=   0.0s\n",
      "[CV 5/5] END ...............C=5298.316906283702;, score=0.777 total time=   0.0s\n",
      "[CV 1/5] END .........................C=10000.0;, score=0.772 total time=   0.0s\n",
      "[CV 2/5] END .........................C=10000.0;, score=0.772 total time=   0.0s\n",
      "[CV 3/5] END .........................C=10000.0;, score=0.775 total time=   0.0s\n",
      "[CV 4/5] END .........................C=10000.0;, score=0.761 total time=   0.0s\n",
      "[CV 5/5] END .........................C=10000.0;, score=0.777 total time=   0.0s\n",
      "0.7720336882461558\n",
      "{'C': 4.893900918477489}\n",
      "0.774671052631579\n"
     ]
    }
   ],
   "source": [
    "# Régularisation Ridge (Standard Scaler)\n",
    "\n",
    "log_reg_s = LogisticRegression(penalty='l2', max_iter=10000)\n",
    "reg_coef =  np.logspace(-4, 4, 30)\n",
    "tuned_parameters = [{'C': reg_coef}]\n",
    "nb_folds = 5\n",
    "grid_s = GridSearchCV(log_reg_s, tuned_parameters, cv=nb_folds, refit=True, verbose=3, scoring='f1')\n",
    "grid_s.fit(X_train_preprocessed_s, y_train)\n",
    "print(grid_s.best_score_)\n",
    "print(grid_s.best_params_)\n",
    "y_pred_s = grid_s.best_estimator_.predict(X_test_preprocessed_s)\n",
    "print(f1_score(y_test, y_pred_s, average='binary'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b96e96-3fb2-440f-a647-92c89c26426f",
   "metadata": {},
   "source": [
    "#### Question 13.c\n",
    "Commentez ce résultat en regard de votre réponse à la question 12."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3548af71",
   "metadata": {},
   "source": [
    "Les résultats obtenus ne sont pas meilleurs, conformément à l'idée de la question 12, et ce quelle que soit la méthode de régularisation et le préprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c07f73-7036-484d-825f-f9675f9fd824",
   "metadata": {},
   "source": [
    "#### Question 14\n",
    "\n",
    "Entraînez une forêt aléatoire sur le jeu d'entraînement et évaluez son F-score sur le jeu de test.\n",
    "\n",
    "__Conseils :__\n",
    "* Vous trouverez les outils nécessaires dans la classe `RandomForestClassifier` du module `ensemble` de `scikit-learn`.\n",
    "* Choisissez le nombre d'arbres par validation croisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "057e8c43-171d-47db-b48d-f1928c0dca6e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GridSearchCV' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-3794288b52b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtuned_parameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'n_estimators'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mreg_coef\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mnb_folds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuned_parameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnb_folds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'f1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_preprocessed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GridSearchCV' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Validation croisée - Forêt aléatoire (Yeo-Johnson)\n",
    "forest = RandomForestClassifier(random_state=13)\n",
    "reg_coef = sorted([i for i in range (1, 10, 3)] + [i for i in range(35, 65, 1)] + [20, 100, 200])\n",
    "tuned_parameters = [{'n_estimators': reg_coef}]\n",
    "nb_folds = 5\n",
    "grid = GridSearchCV(forest, tuned_parameters, cv=nb_folds, refit=True, verbose=3, scoring='f1')\n",
    "grid.fit(X_train_preprocessed, y_train)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "y_pred = grid.best_estimator_.predict(X_test_preprocessed)\n",
    "print(f1_score(y_test, y_pred, average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a23674f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "[CV 1/5] END ....................n_estimators=1;, score=0.845 total time=   0.0s\n",
      "[CV 2/5] END ....................n_estimators=1;, score=0.853 total time=   0.0s\n",
      "[CV 3/5] END ....................n_estimators=1;, score=0.862 total time=   0.0s\n",
      "[CV 4/5] END ....................n_estimators=1;, score=0.843 total time=   0.0s\n",
      "[CV 5/5] END ....................n_estimators=1;, score=0.858 total time=   0.0s\n",
      "[CV 1/5] END ....................n_estimators=4;, score=0.884 total time=   0.0s\n",
      "[CV 2/5] END ....................n_estimators=4;, score=0.880 total time=   0.0s\n",
      "[CV 3/5] END ....................n_estimators=4;, score=0.876 total time=   0.0s\n",
      "[CV 4/5] END ....................n_estimators=4;, score=0.889 total time=   0.0s\n",
      "[CV 5/5] END ....................n_estimators=4;, score=0.892 total time=   0.0s\n",
      "[CV 1/5] END ....................n_estimators=7;, score=0.909 total time=   0.0s\n",
      "[CV 2/5] END ....................n_estimators=7;, score=0.910 total time=   0.1s\n",
      "[CV 3/5] END ....................n_estimators=7;, score=0.905 total time=   0.0s\n",
      "[CV 4/5] END ....................n_estimators=7;, score=0.903 total time=   0.0s\n",
      "[CV 5/5] END ....................n_estimators=7;, score=0.920 total time=   0.0s\n",
      "[CV 1/5] END ...................n_estimators=20;, score=0.929 total time=   0.2s\n",
      "[CV 2/5] END ...................n_estimators=20;, score=0.929 total time=   0.2s\n",
      "[CV 3/5] END ...................n_estimators=20;, score=0.926 total time=   0.3s\n",
      "[CV 4/5] END ...................n_estimators=20;, score=0.921 total time=   0.3s\n",
      "[CV 5/5] END ...................n_estimators=20;, score=0.928 total time=   0.2s\n",
      "[CV 1/5] END ...................n_estimators=35;, score=0.928 total time=   0.4s\n",
      "[CV 2/5] END ...................n_estimators=35;, score=0.930 total time=   0.4s\n",
      "[CV 3/5] END ...................n_estimators=35;, score=0.930 total time=   0.4s\n",
      "[CV 4/5] END ...................n_estimators=35;, score=0.919 total time=   0.4s\n",
      "[CV 5/5] END ...................n_estimators=35;, score=0.935 total time=   0.4s\n",
      "[CV 1/5] END ...................n_estimators=36;, score=0.930 total time=   0.5s\n",
      "[CV 2/5] END ...................n_estimators=36;, score=0.934 total time=   0.5s\n",
      "[CV 3/5] END ...................n_estimators=36;, score=0.933 total time=   0.4s\n",
      "[CV 4/5] END ...................n_estimators=36;, score=0.921 total time=   0.4s\n",
      "[CV 5/5] END ...................n_estimators=36;, score=0.937 total time=   0.4s\n",
      "[CV 1/5] END ...................n_estimators=37;, score=0.930 total time=   0.5s\n",
      "[CV 2/5] END ...................n_estimators=37;, score=0.933 total time=   0.5s\n",
      "[CV 3/5] END ...................n_estimators=37;, score=0.928 total time=   0.5s\n",
      "[CV 4/5] END ...................n_estimators=37;, score=0.916 total time=   0.4s\n",
      "[CV 5/5] END ...................n_estimators=37;, score=0.936 total time=   0.5s\n",
      "[CV 1/5] END ...................n_estimators=38;, score=0.931 total time=   0.4s\n",
      "[CV 2/5] END ...................n_estimators=38;, score=0.937 total time=   0.4s\n",
      "[CV 3/5] END ...................n_estimators=38;, score=0.932 total time=   0.4s\n",
      "[CV 4/5] END ...................n_estimators=38;, score=0.920 total time=   0.4s\n",
      "[CV 5/5] END ...................n_estimators=38;, score=0.937 total time=   0.5s\n",
      "[CV 1/5] END ...................n_estimators=39;, score=0.931 total time=   0.5s\n",
      "[CV 2/5] END ...................n_estimators=39;, score=0.933 total time=   0.5s\n",
      "[CV 3/5] END ...................n_estimators=39;, score=0.930 total time=   0.5s\n",
      "[CV 4/5] END ...................n_estimators=39;, score=0.920 total time=   0.9s\n",
      "[CV 5/5] END ...................n_estimators=39;, score=0.935 total time=   0.5s\n",
      "[CV 1/5] END ...................n_estimators=40;, score=0.931 total time=   0.7s\n",
      "[CV 2/5] END ...................n_estimators=40;, score=0.934 total time=   0.5s\n",
      "[CV 3/5] END ...................n_estimators=40;, score=0.930 total time=   0.5s\n",
      "[CV 4/5] END ...................n_estimators=40;, score=0.922 total time=   0.6s\n",
      "[CV 5/5] END ...................n_estimators=40;, score=0.936 total time=   0.6s\n",
      "[CV 1/5] END ...................n_estimators=41;, score=0.931 total time=   0.6s\n",
      "[CV 2/5] END ...................n_estimators=41;, score=0.933 total time=   0.6s\n",
      "[CV 3/5] END ...................n_estimators=41;, score=0.926 total time=   0.5s\n",
      "[CV 4/5] END ...................n_estimators=41;, score=0.918 total time=   0.5s\n",
      "[CV 5/5] END ...................n_estimators=41;, score=0.933 total time=   0.6s\n",
      "[CV 1/5] END ...................n_estimators=42;, score=0.932 total time=   0.5s\n",
      "[CV 2/5] END ...................n_estimators=42;, score=0.932 total time=   0.5s\n",
      "[CV 3/5] END ...................n_estimators=42;, score=0.931 total time=   0.5s\n",
      "[CV 4/5] END ...................n_estimators=42;, score=0.920 total time=   0.5s\n",
      "[CV 5/5] END ...................n_estimators=42;, score=0.936 total time=   0.7s\n",
      "[CV 1/5] END ...................n_estimators=43;, score=0.930 total time=   0.6s\n",
      "[CV 2/5] END ...................n_estimators=43;, score=0.933 total time=   0.6s\n",
      "[CV 3/5] END ...................n_estimators=43;, score=0.929 total time=   0.5s\n",
      "[CV 4/5] END ...................n_estimators=43;, score=0.918 total time=   0.5s\n",
      "[CV 5/5] END ...................n_estimators=43;, score=0.932 total time=   0.6s\n",
      "[CV 1/5] END ...................n_estimators=44;, score=0.933 total time=   0.6s\n",
      "[CV 2/5] END ...................n_estimators=44;, score=0.935 total time=   0.6s\n",
      "[CV 3/5] END ...................n_estimators=44;, score=0.932 total time=   0.6s\n",
      "[CV 4/5] END ...................n_estimators=44;, score=0.919 total time=   0.6s\n",
      "[CV 5/5] END ...................n_estimators=44;, score=0.936 total time=   0.6s\n",
      "[CV 1/5] END ...................n_estimators=45;, score=0.933 total time=   0.6s\n",
      "[CV 2/5] END ...................n_estimators=45;, score=0.933 total time=   0.6s\n",
      "[CV 3/5] END ...................n_estimators=45;, score=0.930 total time=   0.6s\n",
      "[CV 4/5] END ...................n_estimators=45;, score=0.916 total time=   0.6s\n",
      "[CV 5/5] END ...................n_estimators=45;, score=0.934 total time=   0.6s\n",
      "[CV 1/5] END ...................n_estimators=46;, score=0.935 total time=   0.7s\n",
      "[CV 2/5] END ...................n_estimators=46;, score=0.931 total time=   0.6s\n",
      "[CV 3/5] END ...................n_estimators=46;, score=0.931 total time=   0.6s\n",
      "[CV 4/5] END ...................n_estimators=46;, score=0.919 total time=   0.6s\n",
      "[CV 5/5] END ...................n_estimators=46;, score=0.937 total time=   0.8s\n",
      "[CV 1/5] END ...................n_estimators=47;, score=0.934 total time=   0.8s\n",
      "[CV 2/5] END ...................n_estimators=47;, score=0.930 total time=   0.6s\n",
      "[CV 3/5] END ...................n_estimators=47;, score=0.931 total time=   0.6s\n",
      "[CV 4/5] END ...................n_estimators=47;, score=0.919 total time=   0.8s\n",
      "[CV 5/5] END ...................n_estimators=47;, score=0.937 total time=   0.6s\n",
      "[CV 1/5] END ...................n_estimators=48;, score=0.937 total time=   0.8s\n",
      "[CV 2/5] END ...................n_estimators=48;, score=0.931 total time=   0.7s\n",
      "[CV 3/5] END ...................n_estimators=48;, score=0.933 total time=   0.6s\n",
      "[CV 4/5] END ...................n_estimators=48;, score=0.920 total time=   0.6s\n",
      "[CV 5/5] END ...................n_estimators=48;, score=0.939 total time=   0.5s\n",
      "[CV 1/5] END ...................n_estimators=49;, score=0.934 total time=   0.5s\n",
      "[CV 2/5] END ...................n_estimators=49;, score=0.932 total time=   0.7s\n",
      "[CV 3/5] END ...................n_estimators=49;, score=0.930 total time=   0.6s\n",
      "[CV 4/5] END ...................n_estimators=49;, score=0.920 total time=   0.7s\n",
      "[CV 5/5] END ...................n_estimators=49;, score=0.940 total time=   0.6s\n",
      "[CV 1/5] END ...................n_estimators=50;, score=0.936 total time=   0.7s\n",
      "[CV 2/5] END ...................n_estimators=50;, score=0.934 total time=   0.6s\n",
      "[CV 3/5] END ...................n_estimators=50;, score=0.932 total time=   0.5s\n",
      "[CV 4/5] END ...................n_estimators=50;, score=0.919 total time=   0.6s\n",
      "[CV 5/5] END ...................n_estimators=50;, score=0.940 total time=   0.7s\n",
      "[CV 1/5] END ...................n_estimators=51;, score=0.936 total time=   0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ...................n_estimators=51;, score=0.932 total time=   0.8s\n",
      "[CV 3/5] END ...................n_estimators=51;, score=0.930 total time=   1.0s\n",
      "[CV 4/5] END ...................n_estimators=51;, score=0.922 total time=   0.8s\n",
      "[CV 5/5] END ...................n_estimators=51;, score=0.939 total time=   0.9s\n",
      "[CV 1/5] END ...................n_estimators=52;, score=0.936 total time=   0.9s\n",
      "[CV 2/5] END ...................n_estimators=52;, score=0.933 total time=   0.7s\n",
      "[CV 3/5] END ...................n_estimators=52;, score=0.931 total time=   0.9s\n",
      "[CV 4/5] END ...................n_estimators=52;, score=0.921 total time=   0.7s\n",
      "[CV 5/5] END ...................n_estimators=52;, score=0.939 total time=   0.8s\n",
      "[CV 1/5] END ...................n_estimators=53;, score=0.937 total time=   0.8s\n",
      "[CV 2/5] END ...................n_estimators=53;, score=0.933 total time=   0.8s\n",
      "[CV 3/5] END ...................n_estimators=53;, score=0.931 total time=   0.8s\n",
      "[CV 4/5] END ...................n_estimators=53;, score=0.921 total time=   0.7s\n",
      "[CV 5/5] END ...................n_estimators=53;, score=0.934 total time=   0.8s\n",
      "[CV 1/5] END ...................n_estimators=54;, score=0.938 total time=   0.7s\n",
      "[CV 2/5] END ...................n_estimators=54;, score=0.934 total time=   0.8s\n",
      "[CV 3/5] END ...................n_estimators=54;, score=0.931 total time=   0.9s\n",
      "[CV 4/5] END ...................n_estimators=54;, score=0.920 total time=   0.6s\n",
      "[CV 5/5] END ...................n_estimators=54;, score=0.937 total time=   1.0s\n",
      "[CV 1/5] END ...................n_estimators=55;, score=0.937 total time=   0.9s\n",
      "[CV 2/5] END ...................n_estimators=55;, score=0.932 total time=   0.8s\n",
      "[CV 3/5] END ...................n_estimators=55;, score=0.930 total time=   0.9s\n",
      "[CV 4/5] END ...................n_estimators=55;, score=0.922 total time=   0.7s\n",
      "[CV 5/5] END ...................n_estimators=55;, score=0.936 total time=   0.8s\n",
      "[CV 1/5] END ...................n_estimators=56;, score=0.935 total time=   0.4s\n",
      "[CV 2/5] END ...................n_estimators=56;, score=0.930 total time=   0.5s\n",
      "[CV 3/5] END ...................n_estimators=56;, score=0.932 total time=   0.9s\n",
      "[CV 4/5] END ...................n_estimators=56;, score=0.921 total time=   1.0s\n",
      "[CV 5/5] END ...................n_estimators=56;, score=0.937 total time=   0.8s\n",
      "[CV 1/5] END ...................n_estimators=57;, score=0.939 total time=   0.8s\n",
      "[CV 2/5] END ...................n_estimators=57;, score=0.930 total time=   0.8s\n",
      "[CV 3/5] END ...................n_estimators=57;, score=0.930 total time=   0.8s\n",
      "[CV 4/5] END ...................n_estimators=57;, score=0.922 total time=   0.9s\n",
      "[CV 5/5] END ...................n_estimators=57;, score=0.937 total time=   0.9s\n",
      "[CV 1/5] END ...................n_estimators=58;, score=0.938 total time=   0.9s\n",
      "[CV 2/5] END ...................n_estimators=58;, score=0.931 total time=   1.2s\n",
      "[CV 3/5] END ...................n_estimators=58;, score=0.932 total time=   0.7s\n",
      "[CV 4/5] END ...................n_estimators=58;, score=0.923 total time=   0.8s\n",
      "[CV 5/5] END ...................n_estimators=58;, score=0.939 total time=   0.9s\n",
      "[CV 1/5] END ...................n_estimators=59;, score=0.940 total time=   0.9s\n",
      "[CV 2/5] END ...................n_estimators=59;, score=0.932 total time=   0.8s\n",
      "[CV 3/5] END ...................n_estimators=59;, score=0.929 total time=   0.9s\n",
      "[CV 4/5] END ...................n_estimators=59;, score=0.922 total time=   0.8s\n",
      "[CV 5/5] END ...................n_estimators=59;, score=0.937 total time=   0.8s\n",
      "[CV 1/5] END ...................n_estimators=60;, score=0.936 total time=   0.8s\n",
      "[CV 2/5] END ...................n_estimators=60;, score=0.933 total time=   0.8s\n",
      "[CV 3/5] END ...................n_estimators=60;, score=0.931 total time=   0.7s\n",
      "[CV 4/5] END ...................n_estimators=60;, score=0.920 total time=   0.9s\n",
      "[CV 5/5] END ...................n_estimators=60;, score=0.940 total time=   0.8s\n",
      "[CV 1/5] END ...................n_estimators=61;, score=0.937 total time=   1.2s\n",
      "[CV 2/5] END ...................n_estimators=61;, score=0.932 total time=   0.8s\n",
      "[CV 3/5] END ...................n_estimators=61;, score=0.931 total time=   0.9s\n",
      "[CV 4/5] END ...................n_estimators=61;, score=0.923 total time=   0.8s\n",
      "[CV 5/5] END ...................n_estimators=61;, score=0.940 total time=   0.8s\n",
      "[CV 1/5] END ...................n_estimators=62;, score=0.934 total time=   1.0s\n",
      "[CV 2/5] END ...................n_estimators=62;, score=0.933 total time=   0.8s\n",
      "[CV 3/5] END ...................n_estimators=62;, score=0.933 total time=   0.8s\n",
      "[CV 4/5] END ...................n_estimators=62;, score=0.926 total time=   1.0s\n",
      "[CV 5/5] END ...................n_estimators=62;, score=0.942 total time=   0.9s\n",
      "[CV 1/5] END ...................n_estimators=63;, score=0.938 total time=   0.9s\n",
      "[CV 2/5] END ...................n_estimators=63;, score=0.931 total time=   1.0s\n",
      "[CV 3/5] END ...................n_estimators=63;, score=0.932 total time=   0.9s\n",
      "[CV 4/5] END ...................n_estimators=63;, score=0.922 total time=   0.8s\n",
      "[CV 5/5] END ...................n_estimators=63;, score=0.940 total time=   0.9s\n",
      "[CV 1/5] END ...................n_estimators=64;, score=0.935 total time=   1.0s\n",
      "[CV 2/5] END ...................n_estimators=64;, score=0.929 total time=   0.9s\n",
      "[CV 3/5] END ...................n_estimators=64;, score=0.933 total time=   0.6s\n",
      "[CV 4/5] END ...................n_estimators=64;, score=0.925 total time=   0.9s\n",
      "[CV 5/5] END ...................n_estimators=64;, score=0.942 total time=   0.9s\n",
      "[CV 1/5] END ..................n_estimators=100;, score=0.931 total time=   1.5s\n",
      "[CV 2/5] END ..................n_estimators=100;, score=0.932 total time=   1.4s\n",
      "[CV 3/5] END ..................n_estimators=100;, score=0.931 total time=   1.5s\n",
      "[CV 4/5] END ..................n_estimators=100;, score=0.927 total time=   1.4s\n",
      "[CV 5/5] END ..................n_estimators=100;, score=0.933 total time=   1.4s\n",
      "[CV 1/5] END ..................n_estimators=200;, score=0.932 total time=   3.1s\n",
      "[CV 2/5] END ..................n_estimators=200;, score=0.932 total time=   3.0s\n",
      "[CV 3/5] END ..................n_estimators=200;, score=0.930 total time=   3.0s\n",
      "[CV 4/5] END ..................n_estimators=200;, score=0.929 total time=   3.0s\n",
      "[CV 5/5] END ..................n_estimators=200;, score=0.933 total time=   2.9s\n",
      "0.933832138253788\n",
      "{'n_estimators': 62}\n",
      "0.9390739236393176\n"
     ]
    }
   ],
   "source": [
    "# Validation croisée - Forêt aléatoire (Standard Scaler)\n",
    "\n",
    "forest_s = RandomForestClassifier(random_state=13)\n",
    "reg_coef = sorted([i for i in range (1, 10, 3)] + [i for i in range(35, 65, 1)] + [20, 100, 200])\n",
    "tuned_parameters = [{'n_estimators': reg_coef}]\n",
    "nb_folds = 5\n",
    "grid_s = GridSearchCV(forest_s, tuned_parameters, cv=nb_folds, refit=True, verbose=3, scoring='f1')\n",
    "grid_s.fit(X_train_preprocessed_s, y_train)\n",
    "print(grid_s.best_score_)\n",
    "print(grid_s.best_params_)\n",
    "y_pred_s = grid_s.best_estimator_.predict(X_test_preprocessed_s)\n",
    "print(f1_score(y_test, y_pred_s, average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3711d658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeu d'entrainement 1.0\n",
      "Jeu de test 0.916463909164639\n"
     ]
    }
   ],
   "source": [
    "# Jeu de test (Yeo-Johnson)\n",
    "\n",
    "forest = RandomForestClassifier(random_state=13, n_estimators=62)\n",
    "forest.fit(X_train_preprocessed, y_train)\n",
    "print(\"Jeu d'entrainement\", f1_score(y_train, forest.predict(X_train_preprocessed), average='binary'))\n",
    "print(\"Jeu de test\", f1_score(y_test, forest.predict(X_test_preprocessed), average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "73c48d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeu d'entrainement 1.0\n",
      "Jeu de test 0.9353796445880452\n"
     ]
    }
   ],
   "source": [
    "# Jeu de test (Standard Scaler)\n",
    "\n",
    "forest_s = RandomForestClassifier(random_state=13, n_estimators=38)\n",
    "forest_s.fit(X_train_preprocessed_s, y_train)\n",
    "print(\"Jeu d'entrainement\", f1_score(y_train, forest_s.predict(X_train_preprocessed_s), average='binary'))\n",
    "print(\"Jeu de test\", f1_score(y_test, forest_s.predict(X_test_preprocessed_s), average='binary'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e006c52b",
   "metadata": {},
   "source": [
    "Globalement, malgré un fort surapprentissage, les résultats sont excellents sur le jeu de test pour les forêts aléatoires et meilleurs que pour les autres modèles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bf8638-7c60-4b36-9266-0dcc83bd2e8f",
   "metadata": {},
   "source": [
    "## Modèle final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fe7ea4-f2c3-4567-8184-9d73e3b98526",
   "metadata": {},
   "source": [
    "#### Question 15.a\n",
    "Visualisez les performances des différents modèles (et pré-traitements) que vous avez évalués sur le jeu de test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e343d83f",
   "metadata": {},
   "source": [
    "Sur le jeu de test, on obtient les F-scores suivants :\n",
    "\n",
    "|                                                                          | Yeo-Johnson     | StandardScaler  |\n",
    "|--------------------------------------------------------------------------|-----------------|-----------------|\n",
    "| Toujours des positifs | 0.67 | 0.67 |\n",
    "| KNN <br> 1 voisin<br> 3 voisins<br>5 voisins                                                        |  <br>0.88 <br>0.87 <br>0.86 |  <br>0.91<br>0.90<br>0.90 |\n",
    "| LogisticRegression <br>     sans régularisation<br>avec un lasso<br>avec un ridge | <br>0.71<br>0.71<br>0.71            | <br>0.77<br>0.78<br>0.77          |\n",
    "| ForestClassifier <br>38 arbres<br>62 arbres                                               | <br>0.91<br>0.92            | <br>0.94<br>0.94            |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133426fd-c186-4b43-b979-70215480efaf",
   "metadata": {},
   "source": [
    "#### Question 15.b\n",
    "Utilisez cette figure pour __sélectionner votre modèle favori__. Quel pré-traitement choisissez-vous ? Quel algorithme choisissez-vous, avec quel hyper-paramètre ? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91128eae",
   "metadata": {},
   "source": [
    "En se basant sur le tableau ci-dessus, mais surtout à partir des résultats de la validation croisée, le modèle favori est la forêt aléatoire précédé du traitement StandardScaler, avec un hyperparamètre 'n_estimators' de 62 arbres.\n",
    "\n",
    "En effet, en cas de contradiction entre la validation croisée et le tableau ci-dessus, on choisit la valeur des hyperparamètres par validation croisée, plutôt que sur le seul jeu de test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce64660-fb7a-4849-b59d-c6624fed6742",
   "metadata": {},
   "source": [
    "#### Question 16.a\n",
    "Chargez les données privées de `data/foret_prive.tsv` pour obtenir un array `X_private`. Le fichier suit la même syntaxe que `data/foret_public.tsv`, mais sans la colonne des étiquettes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "229653f4-f509-4c99-b5c1-80617ab35b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_private = pd.read_csv('data/foret_prive.tsv', delimiter='\\t') # lecture dataframe privé\n",
    "X_private = np.array(df_private) # Il n'y a pas de colonnes \"espèce\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d60735-a40d-48d7-869b-d337bcd95077",
   "metadata": {},
   "source": [
    "#### Question 16.b\n",
    "Appliquez le pré-traitement que vous avez choisi à l'intégralité du jeu de données public `X_public` pour obtenir `X_public_preprocessed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bae0c4bb-a824-4263-b386-e155e009ca40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "s_scaler = preprocessing.StandardScaler()\n",
    "s_scaler.fit(X_public)\n",
    "X_public_preprocessed_s = s_scaler.transform(X_public)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c1fb7c-ffe7-470f-b58b-8041c9b10330",
   "metadata": {},
   "source": [
    "#### Question 16.c\n",
    "Appliquez à `X_private` le pré-traitement que vous avez choisi ; enregistrez le résultat dans `X_private_preprocessed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "254e1192-0182-402d-8d4d-70de64973407",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_private_preprocessed_s = s_scaler.transform(X_private)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4bb670-3f6d-4047-bc90-1fc978172854",
   "metadata": {},
   "source": [
    "#### Question 16.d\n",
    "Entraînez l'algorithme que vous avez sélectionné sur l'intégralité des données publiques `(X_public_processed, y_public)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d91647fe-70f5-49b2-8ef3-fb7e015be967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=62, random_state=13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_s = RandomForestClassifier(random_state=13, n_estimators=62)\n",
    "forest_s.fit(X_public_preprocessed_s, y_public)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e2c093-fa21-48ff-a0e6-6a747740edbc",
   "metadata": {},
   "source": [
    "#### Question 16.e\n",
    "Prédisez les étiquettes de `X_private_preprocessed` ; enregistrez le résultat dans un array `y_pred_final`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9107f388-d6ec-48cd-bff7-abf0712cb3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final = forest_s.predict(X_private_preprocessed_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f05b749-386e-460f-955d-c6e4d3852e13",
   "metadata": {},
   "source": [
    "#### Question 16.f\n",
    "Utilisez le code suivant pour créer le fichier de prédictions que vous rendrez. \n",
    "\n",
    "__Attention__ Si vous ouvrez ce fichier avec un programme externe type Microsoft Excel ou LibreOffice Calc pour le lire, il est possible que ce programme modifie le fichier sans que vous ne le réalisiez. Préférez utiliser une commande bash type `less` ou `cat` ou éditeur de texte simple ; ou alors assurez-vous de relancer la commande."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bd3d46b-ea54-4029-9742-c68719b25f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save array to file\n",
    "np.savetxt(\"test_file.tsv\", \n",
    "           y_pred_final,\n",
    "           fmt=('%d'), \n",
    "           header='Prediction',\n",
    "           delimiter='\\t', comments=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba074584-047b-4423-8cc5-1398a31d0bae",
   "metadata": {},
   "source": [
    "## Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744665a6-49fe-4d64-95a9-95e20dec9517",
   "metadata": {},
   "source": [
    "1. En alternative au F-score, utilisez des courbes ROC (et l'aire sous ces courbes) pour comparer vos modèles. Attention à utiliser les méthodes `predict_proba()` plutôt que `predict()` pour obtenir des scores non-seuillés plutôt que des prédictions binaires. Documentation pertinente : https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_roc_curve.html et  https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html.\n",
    "\n",
    "1. Explorez d'autres pré-traitements (comme par exemple le fait de réduire la dimension des données) et d'autres algorithmes d'apprentissage implémentés dans scikit-learn (par exemple SVM, perceptrons multi-couches) pour essayer d'améliorer vos prédictions et reprenez la question 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b1baa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d5cf09ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Comparaison des courbes ROC pour le modèle de régression logistique et de forêt aléatoire avec le prétraitement StandardScaler')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Courbes ROC pour la régression logistique avec Standard Scaler\n",
    "\n",
    "log_reg = LogisticRegression(penalty='l1', max_iter=10000, solver='saga') # default C\n",
    "log_reg.fit(X_train_preprocessed_s, y_train)\n",
    "forest = RandomForestClassifier(random_state=13, n_estimators=38)\n",
    "forest.fit(X_train_preprocessed_s, y_train)\n",
    "\n",
    "metrics.plot_roc_curve(log_reg, X_test_preprocessed_s, y_test, response_method='predict_proba');\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, forest.predict_proba(X_test_preprocessed_s)[:,1])\n",
    "plt.plot(fpr, tpr, label=f'RandomForestClassifier (AUC = {metrics.roc_auc_score(y_test, forest.predict_proba(X_test_preprocessed_s)[:,1]):.2f})')\n",
    "plt.plot([0,0,1],[0,1,1], ':', label=\"Ideal curve (AUC = 1.00)\")\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, [1.]*len(y_test))\n",
    "plt.plot(fpr, tpr, ':',label=f'Random model (AUC = {metrics.roc_auc_score(y_test, [1.]*len(y_test)):.2f})')\n",
    "plt.legend()\n",
    "plt.title(\"Comparaison des courbes ROC pour le modèle de régression logistique et de forêt aléatoire avec le prétraitement StandardScaler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4679c83e",
   "metadata": {},
   "source": [
    "On constate bien que la courbe RandomForest est plus proche de l'idéal que la courbe de LogisticRegression, avec une aire sous la courbe plus proche de 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c036d29c",
   "metadata": {},
   "source": [
    "### 2. Autres prétraitrements et modèles\n",
    "\n",
    "On peut essayer d'autres prétraitements et modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70f0cbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4800, 10)\n",
      "(4800, 2)\n",
      "[0.29817933 0.1985973 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import decomposition\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Analyse en composantes principales (on pourrait faire une sélection de variables également) à partir du prétraitement StandardScaler\n",
    "\n",
    "pca = decomposition.PCA(n_components=2)\n",
    "pca.fit(X_train_preprocessed_s)\n",
    "X_train_preprocessed_projected_s = pca.transform(X_train_preprocessed_s)\n",
    "X_test_preprocessed_projected_s = pca.transform(X_test_preprocessed_s)\n",
    "print(X_train_preprocessed_s.shape)\n",
    "print(X_train_preprocessed_projected_s.shape)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f428b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV 1/5] END ....................n_estimators=1;, score=0.580 total time=   0.0s\n",
      "[CV 2/5] END ....................n_estimators=1;, score=0.590 total time=   0.0s\n",
      "[CV 3/5] END ....................n_estimators=1;, score=0.625 total time=   0.0s\n",
      "[CV 4/5] END ....................n_estimators=1;, score=0.588 total time=   0.0s\n",
      "[CV 5/5] END ....................n_estimators=1;, score=0.577 total time=   0.0s\n",
      "[CV 1/5] END ....................n_estimators=4;, score=0.547 total time=   0.0s\n",
      "[CV 2/5] END ....................n_estimators=4;, score=0.527 total time=   0.0s\n",
      "[CV 3/5] END ....................n_estimators=4;, score=0.587 total time=   0.0s\n",
      "[CV 4/5] END ....................n_estimators=4;, score=0.559 total time=   0.0s\n",
      "[CV 5/5] END ....................n_estimators=4;, score=0.527 total time=   0.0s\n",
      "[CV 1/5] END ....................n_estimators=7;, score=0.585 total time=   0.0s\n",
      "[CV 2/5] END ....................n_estimators=7;, score=0.625 total time=   0.0s\n",
      "[CV 3/5] END ....................n_estimators=7;, score=0.615 total time=   0.0s\n",
      "[CV 4/5] END ....................n_estimators=7;, score=0.616 total time=   0.0s\n",
      "[CV 5/5] END ....................n_estimators=7;, score=0.589 total time=   0.0s\n",
      "[CV 1/5] END ...................n_estimators=20;, score=0.583 total time=   0.0s\n",
      "[CV 2/5] END ...................n_estimators=20;, score=0.612 total time=   0.0s\n",
      "[CV 3/5] END ...................n_estimators=20;, score=0.597 total time=   0.0s\n",
      "[CV 4/5] END ...................n_estimators=20;, score=0.615 total time=   0.0s\n",
      "[CV 5/5] END ...................n_estimators=20;, score=0.612 total time=   0.0s\n",
      "[CV 1/5] END ...................n_estimators=40;, score=0.596 total time=   0.1s\n",
      "[CV 2/5] END ...................n_estimators=40;, score=0.621 total time=   0.1s\n",
      "[CV 3/5] END ...................n_estimators=40;, score=0.610 total time=   0.1s\n",
      "[CV 4/5] END ...................n_estimators=40;, score=0.601 total time=   0.1s\n",
      "[CV 5/5] END ...................n_estimators=40;, score=0.617 total time=   0.1s\n",
      "[CV 1/5] END ...................n_estimators=60;, score=0.600 total time=   0.2s\n",
      "[CV 2/5] END ...................n_estimators=60;, score=0.626 total time=   0.2s\n",
      "[CV 3/5] END ...................n_estimators=60;, score=0.606 total time=   0.2s\n",
      "[CV 4/5] END ...................n_estimators=60;, score=0.615 total time=   0.2s\n",
      "[CV 5/5] END ...................n_estimators=60;, score=0.610 total time=   0.2s\n",
      "[CV 1/5] END ..................n_estimators=100;, score=0.598 total time=   0.3s\n",
      "[CV 2/5] END ..................n_estimators=100;, score=0.627 total time=   0.4s\n",
      "[CV 3/5] END ..................n_estimators=100;, score=0.610 total time=   0.3s\n",
      "[CV 4/5] END ..................n_estimators=100;, score=0.617 total time=   0.3s\n",
      "[CV 5/5] END ..................n_estimators=100;, score=0.600 total time=   0.3s\n",
      "[CV 1/5] END ..................n_estimators=200;, score=0.607 total time=   0.7s\n",
      "[CV 2/5] END ..................n_estimators=200;, score=0.635 total time=   0.7s\n",
      "[CV 3/5] END ..................n_estimators=200;, score=0.613 total time=   0.7s\n",
      "[CV 4/5] END ..................n_estimators=200;, score=0.626 total time=   0.8s\n",
      "[CV 5/5] END ..................n_estimators=200;, score=0.600 total time=   0.8s\n",
      "0.616152885593557\n",
      "{'n_estimators': 200}\n",
      "0.6351351351351352\n"
     ]
    }
   ],
   "source": [
    "# Forêt aléatoire (validation croisée) sur la projection\n",
    "\n",
    "reg_coef = sorted([i for i in range (1, 10, 3)] + [20, 40, 60, 100, 200])\n",
    "tuned_parameters = [{'n_estimators': reg_coef}]\n",
    "nb_folds = 5\n",
    "\n",
    "forest2 = RandomForestClassifier(random_state=13)\n",
    "grid = GridSearchCV(forest2, tuned_parameters, cv=nb_folds, refit=True, verbose=3, scoring='f1')\n",
    "grid.fit(X_train_preprocessed_projected_s, y_train)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "y_pred = grid.best_estimator_.predict(X_test_preprocessed_projected_s)\n",
    "print(f1_score(y_test, y_pred, average='binary'))\n",
    "\n",
    "# On pourrait étudier l'hyperparamètre de la dimension dans laquelle on projette"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd38eb0",
   "metadata": {},
   "source": [
    "Ce modèle fait pire que répondre toujours positif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "05b94785",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron 0.5756385068762279\n",
      "Réseau de neurones 0.9053627760252365\n"
     ]
    }
   ],
   "source": [
    "# Perceptron\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "perceptron = Perceptron(tol=1e-3, random_state=0)\n",
    "perceptron.fit(X_train_preprocessed_s, y_train)\n",
    "print(\"Perceptron\", f1_score(y_test, perceptron.predict(X_test_preprocessed_s), average='binary'))\n",
    "\n",
    "perceptron_ml = MLPClassifier(random_state=13, max_iter=10000).fit(X_train_preprocessed_s, y_train)\n",
    "print(\"Réseau de neurones\", f1_score(y_test, perceptron_ml.predict(X_test_preprocessed_s), average='binary'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920928f3",
   "metadata": {},
   "source": [
    "Le perceptron fournit des résultats pires que de répondre toujours positifs : il n'est pas un modèle à choisir.\n",
    "Le réseau de neurones donne des résultats corrects, même s'ils ne sont pas aussi bons que ceux de la forêt aléatoire. Il faudrait sûrement essayer de choisir les hyperparamètres de ce modèle par validation croisée et analyse pour améliorer ce résultat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6fec2268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.871559633027523\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# SVM\n",
    "\n",
    "svc_model = svm.SVC()\n",
    "svc_model.fit(X_train_preprocessed_s, y_train)\n",
    "print(f1_score(y_test, svc_model.predict(X_test_preprocessed_s), average='binary'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bca5ac9",
   "metadata": {},
   "source": [
    "On constate un F-score moyen pour le modèle SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc82af1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
